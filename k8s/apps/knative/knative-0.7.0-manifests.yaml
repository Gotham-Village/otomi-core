apiVersion: v1
items:
- apiVersion: v1
  kind: Namespace
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Namespace","metadata":{"annotations":{},"labels":{"istio-injection":"enabled","serving.knative.dev/release":"v0.7.0"},"name":"knative-serving"}}
    labels:
      istio-injection: enabled
      serving.knative.dev/release: v0.7.0
    name: knative-serving
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"networking.knative.dev/certificate-provider":"cert-manager","serving.knative.dev/controller":"true","serving.knative.dev/release":"v0.7.0"},"name":"knative-serving-certmanager"},"rules":[{"apiGroups":["certmanager.k8s.io"],"resources":["certificates"],"verbs":["get","list","create","update","delete","patch","watch"]}]}
    labels:
      networking.knative.dev/certificate-provider: cert-manager
      serving.knative.dev/controller: "true"
      serving.knative.dev/release: v0.7.0
    name: knative-serving-certmanager
  rules:
  - apiGroups:
    - certmanager.k8s.io
    resources:
    - certificates
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"networking.knative.dev/ingress-provider":"istio","serving.knative.dev/controller":"true","serving.knative.dev/release":"v0.7.0"},"name":"knative-serving-istio"},"rules":[{"apiGroups":["networking.istio.io"],"resources":["virtualservices","gateways"],"verbs":["get","list","create","update","delete","patch","watch"]}]}
    labels:
      networking.knative.dev/ingress-provider: istio
      serving.knative.dev/controller: "true"
      serving.knative.dev/release: v0.7.0
    name: knative-serving-istio
  rules:
  - apiGroups:
    - networking.istio.io
    resources:
    - virtualservices
    - gateways
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"autoscaling.knative.dev/metric-provider":"custom-metrics","serving.knative.dev/release":"v0.7.0"},"name":"custom-metrics-server-resources"},"rules":[{"apiGroups":["custom.metrics.k8s.io"],"resources":["*"],"verbs":["*"]}]}
    labels:
      autoscaling.knative.dev/metric-provider: custom-metrics
      serving.knative.dev/release: v0.7.0
    name: custom-metrics-server-resources
  rules:
  - apiGroups:
    - custom.metrics.k8s.io
    resources:
    - '*'
    verbs:
    - '*'
- aggregationRule:
    clusterRoleSelectors:
    - matchLabels:
        serving.knative.dev/controller: "true"
  apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"aggregationRule":{"clusterRoleSelectors":[{"matchLabels":{"serving.knative.dev/controller":"true"}}]},"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"serving.knative.dev/release":"v0.7.0"},"name":"knative-serving-admin"},"rules":[]}
    labels:
      serving.knative.dev/release: v0.7.0
    name: knative-serving-admin
  rules: []
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"serving.knative.dev/controller":"true","serving.knative.dev/release":"v0.7.0"},"name":"knative-serving-core"},"rules":[{"apiGroups":[""],"resources":["pods","namespaces","secrets","configmaps","endpoints","services","events","serviceaccounts"],"verbs":["get","list","create","update","delete","patch","watch"]},{"apiGroups":[""],"resources":["endpoints/restricted"],"verbs":["create"]},{"apiGroups":["apps"],"resources":["deployments","deployments/finalizers"],"verbs":["get","list","create","update","delete","patch","watch"]},{"apiGroups":["admissionregistration.k8s.io"],"resources":["mutatingwebhookconfigurations"],"verbs":["get","list","create","update","delete","patch","watch"]},{"apiGroups":["apiextensions.k8s.io"],"resources":["customresourcedefinitions"],"verbs":["get","list","create","update","delete","patch","watch"]},{"apiGroups":["autoscaling"],"resources":["horizontalpodautoscalers"],"verbs":["get","list","create","update","delete","patch","watch"]},{"apiGroups":["serving.knative.dev","autoscaling.internal.knative.dev","networking.internal.knative.dev"],"resources":["*","*/status","*/finalizers"],"verbs":["get","list","create","update","delete","deletecollection","patch","watch"]},{"apiGroups":["caching.internal.knative.dev"],"resources":["images"],"verbs":["get","list","create","update","delete","patch","watch"]}]}
    labels:
      serving.knative.dev/controller: "true"
      serving.knative.dev/release: v0.7.0
    name: knative-serving-core
  rules:
  - apiGroups:
    - ""
    resources:
    - pods
    - namespaces
    - secrets
    - configmaps
    - endpoints
    - services
    - events
    - serviceaccounts
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
  - apiGroups:
    - ""
    resources:
    - endpoints/restricted
    verbs:
    - create
  - apiGroups:
    - apps
    resources:
    - deployments
    - deployments/finalizers
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
  - apiGroups:
    - admissionregistration.k8s.io
    resources:
    - mutatingwebhookconfigurations
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
  - apiGroups:
    - apiextensions.k8s.io
    resources:
    - customresourcedefinitions
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
  - apiGroups:
    - autoscaling
    resources:
    - horizontalpodautoscalers
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
  - apiGroups:
    - serving.knative.dev
    - autoscaling.internal.knative.dev
    - networking.internal.knative.dev
    resources:
    - '*'
    - '*/status'
    - '*/finalizers'
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - deletecollection
    - patch
    - watch
  - apiGroups:
    - caching.internal.knative.dev
    resources:
    - images
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"ServiceAccount","metadata":{"annotations":{},"labels":{"serving.knative.dev/release":"v0.7.0"},"name":"controller","namespace":"knative-serving"}}
    labels:
      serving.knative.dev/release: v0.7.0
    name: controller
    namespace: knative-serving
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"labels":{"autoscaling.knative.dev/metric-provider":"custom-metrics","serving.knative.dev/release":"v0.7.0"},"name":"custom-metrics:system:auth-delegator"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"system:auth-delegator"},"subjects":[{"kind":"ServiceAccount","name":"controller","namespace":"knative-serving"}]}
    labels:
      autoscaling.knative.dev/metric-provider: custom-metrics
      serving.knative.dev/release: v0.7.0
    name: custom-metrics:system:auth-delegator
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:auth-delegator
  subjects:
  - kind: ServiceAccount
    name: controller
    namespace: knative-serving
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"labels":{"autoscaling.knative.dev/metric-provider":"custom-metrics","serving.knative.dev/release":"v0.7.0"},"name":"hpa-controller-custom-metrics"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"custom-metrics-server-resources"},"subjects":[{"kind":"ServiceAccount","name":"horizontal-pod-autoscaler","namespace":"kube-system"}]}
    labels:
      autoscaling.knative.dev/metric-provider: custom-metrics
      serving.knative.dev/release: v0.7.0
    name: hpa-controller-custom-metrics
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: custom-metrics-server-resources
  subjects:
  - kind: ServiceAccount
    name: horizontal-pod-autoscaler
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"labels":{"serving.knative.dev/release":"v0.7.0"},"name":"knative-serving-controller-admin"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"knative-serving-admin"},"subjects":[{"kind":"ServiceAccount","name":"controller","namespace":"knative-serving"}]}
    labels:
      serving.knative.dev/release: v0.7.0
    name: knative-serving-controller-admin
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: knative-serving-admin
  subjects:
  - kind: ServiceAccount
    name: controller
    namespace: knative-serving
- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"RoleBinding","metadata":{"annotations":{},"labels":{"autoscaling.knative.dev/metric-provider":"custom-metrics","serving.knative.dev/release":"v0.7.0"},"name":"custom-metrics-auth-reader","namespace":"kube-system"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"Role","name":"extension-apiserver-authentication-reader"},"subjects":[{"kind":"ServiceAccount","name":"controller","namespace":"knative-serving"}]}
    labels:
      autoscaling.knative.dev/metric-provider: custom-metrics
      serving.knative.dev/release: v0.7.0
    name: custom-metrics-auth-reader
    namespace: kube-system
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: extension-apiserver-authentication-reader
  subjects:
  - kind: ServiceAccount
    name: controller
    namespace: knative-serving
- apiVersion: networking.istio.io/v1alpha3
  kind: Gateway
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"networking.istio.io/v1alpha3","kind":"Gateway","metadata":{"annotations":{},"labels":{"networking.knative.dev/ingress-provider":"istio","serving.knative.dev/release":"v0.7.0"},"name":"knative-ingress-gateway","namespace":"knative-serving"},"spec":{"selector":{"istio":"ingressgateway"},"servers":[{"hosts":["*"],"port":{"name":"http","number":80,"protocol":"HTTP"}},{"hosts":["*"],"port":{"name":"https","number":443,"protocol":"HTTPS"},"tls":{"mode":"PASSTHROUGH"}}]}}
    labels:
      networking.knative.dev/ingress-provider: istio
      serving.knative.dev/release: v0.7.0
    name: knative-ingress-gateway
    namespace: knative-serving
  spec:
    selector:
      istio: ingressgateway
    servers:
    - hosts:
      - '*'
      port:
        name: http
        number: 80
        protocol: HTTP
    - hosts:
      - '*'
      port:
        name: https
        number: 443
        protocol: HTTPS
      tls:
        mode: PASSTHROUGH
- apiVersion: networking.istio.io/v1alpha3
  kind: Gateway
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"networking.istio.io/v1alpha3","kind":"Gateway","metadata":{"annotations":{},"labels":{"networking.knative.dev/ingress-provider":"istio","serving.knative.dev/release":"v0.7.0"},"name":"cluster-local-gateway","namespace":"knative-serving"},"spec":{"selector":{"istio":"cluster-local-gateway"},"servers":[{"hosts":["*"],"port":{"name":"http","number":80,"protocol":"HTTP"}}]}}
    labels:
      networking.knative.dev/ingress-provider: istio
      serving.knative.dev/release: v0.7.0
    name: cluster-local-gateway
    namespace: knative-serving
  spec:
    selector:
      istio: cluster-local-gateway
    servers:
    - hosts:
      - '*'
      port:
        name: http
        number: 80
        protocol: HTTP
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"app":"activator","serving.knative.dev/release":"v0.7.0"},"name":"activator-service","namespace":"knative-serving"},"spec":{"ports":[{"name":"http","port":80,"protocol":"TCP","targetPort":8012},{"name":"http2","port":81,"protocol":"TCP","targetPort":8013},{"name":"metrics","port":9090,"protocol":"TCP","targetPort":9090}],"selector":{"app":"activator"},"type":"ClusterIP"}}
    labels:
      app: activator
      serving.knative.dev/release: v0.7.0
    name: activator-service
    namespace: knative-serving
  spec:
    ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: 8012
    - name: http2
      port: 81
      protocol: TCP
      targetPort: 8013
    - name: metrics
      port: 9090
      protocol: TCP
      targetPort: 9090
    selector:
      app: activator
    type: ClusterIP
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"app":"controller","serving.knative.dev/release":"v0.7.0"},"name":"controller","namespace":"knative-serving"},"spec":{"ports":[{"name":"metrics","port":9090,"protocol":"TCP","targetPort":9090}],"selector":{"app":"controller"}}}
    labels:
      app: controller
      serving.knative.dev/release: v0.7.0
    name: controller
    namespace: knative-serving
  spec:
    ports:
    - name: metrics
      port: 9090
      protocol: TCP
      targetPort: 9090
    selector:
      app: controller
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"role":"webhook","serving.knative.dev/release":"v0.7.0"},"name":"webhook","namespace":"knative-serving"},"spec":{"ports":[{"port":443,"targetPort":8443}],"selector":{"role":"webhook"}}}
    labels:
      role: webhook
      serving.knative.dev/release: v0.7.0
    name: webhook
    namespace: knative-serving
  spec:
    ports:
    - port: 443
      targetPort: 8443
    selector:
      role: webhook
- apiVersion: caching.internal.knative.dev/v1alpha1
  kind: Image
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"caching.internal.knative.dev/v1alpha1","kind":"Image","metadata":{"annotations":{},"labels":{"serving.knative.dev/release":"v0.7.0"},"name":"queue-proxy","namespace":"knative-serving"},"spec":{"image":"gcr.io/knative-releases/github.com/knative/serving/cmd/queue@sha256:e007c0a78c541600466f88954deee65c517246a23345bfba45a7f212d09b8f3b"}}
    labels:
      serving.knative.dev/release: v0.7.0
    name: queue-proxy
    namespace: knative-serving
  spec:
    image: gcr.io/knative-releases/github.com/knative/serving/cmd/queue@sha256:e007c0a78c541600466f88954deee65c517246a23345bfba45a7f212d09b8f3b
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"serving.knative.dev/release":"v0.7.0"},"name":"activator","namespace":"knative-serving"},"spec":{"selector":{"matchLabels":{"app":"activator","role":"activator"}},"template":{"metadata":{"annotations":{"cluster-autoscaler.kubernetes.io/safe-to-evict":"false","sidecar.istio.io/inject":"true"},"labels":{"app":"activator","role":"activator","serving.knative.dev/release":"v0.7.0"}},"spec":{"containers":[{"args":["-logtostderr=false","-stderrthreshold=FATAL"],"env":[{"name":"POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"SYSTEM_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}},{"name":"CONFIG_LOGGING_NAME","value":"config-logging"},{"name":"CONFIG_OBSERVABILITY_NAME","value":"config-observability"},{"name":"METRICS_DOMAIN","value":"knative.dev/serving"}],"image":"gcr.io/knative-releases/github.com/knative/serving/cmd/activator@sha256:57fe5f1a8b1d12f29fe9e3a904b00c7219e5ce5825d94f33339db929e92257db","livenessProbe":{"httpGet":{"httpHeaders":[{"name":"k-kubelet-probe","value":"activator"}],"path":"/healthz","port":8012}},"name":"activator","ports":[{"containerPort":8012,"name":"http1-port"},{"containerPort":8013,"name":"h2c-port"},{"containerPort":9090,"name":"metrics-port"}],"readinessProbe":{"httpGet":{"httpHeaders":[{"name":"k-kubelet-probe","value":"activator"}],"path":"/healthz","port":8012}},"resources":{"limits":{"cpu":"200m","memory":"600Mi"},"requests":{"cpu":"20m","memory":"60Mi"}},"securityContext":{"allowPrivilegeEscalation":false},"volumeMounts":[{"mountPath":"/etc/config-logging","name":"config-logging"},{"mountPath":"/etc/config-observability","name":"config-observability"}]}],"serviceAccountName":"controller","volumes":[{"configMap":{"name":"config-logging"},"name":"config-logging"},{"configMap":{"name":"config-observability"},"name":"config-observability"}]}}}}
    labels:
      serving.knative.dev/release: v0.7.0
    name: activator
    namespace: knative-serving
  spec:
    selector:
      matchLabels:
        app: activator
        role: activator
    template:
      metadata:
        annotations:
          cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
          sidecar.istio.io/inject: "true"
        labels:
          app: activator
          role: activator
          serving.knative.dev/release: v0.7.0
      spec:
        containers:
        - args:
          - -logtostderr=false
          - -stderrthreshold=FATAL
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          - name: SYSTEM_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: CONFIG_LOGGING_NAME
            value: config-logging
          - name: CONFIG_OBSERVABILITY_NAME
            value: config-observability
          - name: METRICS_DOMAIN
            value: knative.dev/serving
          image: gcr.io/knative-releases/github.com/knative/serving/cmd/activator@sha256:57fe5f1a8b1d12f29fe9e3a904b00c7219e5ce5825d94f33339db929e92257db
          livenessProbe:
            httpGet:
              httpHeaders:
              - name: k-kubelet-probe
                value: activator
              path: /healthz
              port: 8012
          name: activator
          ports:
          - containerPort: 8012
            name: http1-port
          - containerPort: 8013
            name: h2c-port
          - containerPort: 9090
            name: metrics-port
          readinessProbe:
            httpGet:
              httpHeaders:
              - name: k-kubelet-probe
                value: activator
              path: /healthz
              port: 8012
          resources:
            limits:
              cpu: 200m
              memory: 600Mi
            requests:
              cpu: 20m
              memory: 60Mi
          securityContext:
            allowPrivilegeEscalation: false
          volumeMounts:
          - mountPath: /etc/config-logging
            name: config-logging
          - mountPath: /etc/config-observability
            name: config-observability
        serviceAccountName: controller
        volumes:
        - configMap:
            name: config-logging
          name: config-logging
        - configMap:
            name: config-observability
          name: config-observability
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"app":"autoscaler","serving.knative.dev/release":"v0.7.0"},"name":"autoscaler","namespace":"knative-serving"},"spec":{"ports":[{"name":"http","port":8080,"protocol":"TCP","targetPort":8080},{"name":"metrics","port":9090,"protocol":"TCP","targetPort":9090},{"name":"custom-metrics","port":443,"protocol":"TCP","targetPort":8443}],"selector":{"app":"autoscaler"}}}
    labels:
      app: autoscaler
      serving.knative.dev/release: v0.7.0
    name: autoscaler
    namespace: knative-serving
  spec:
    ports:
    - name: http
      port: 8080
      protocol: TCP
      targetPort: 8080
    - name: metrics
      port: 9090
      protocol: TCP
      targetPort: 9090
    - name: custom-metrics
      port: 443
      protocol: TCP
      targetPort: 8443
    selector:
      app: autoscaler
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"serving.knative.dev/release":"v0.7.0"},"name":"autoscaler","namespace":"knative-serving"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"autoscaler"}},"template":{"metadata":{"annotations":{"cluster-autoscaler.kubernetes.io/safe-to-evict":"false","sidecar.istio.io/inject":"true"},"labels":{"app":"autoscaler","serving.knative.dev/release":"v0.7.0"}},"spec":{"containers":[{"args":["--secure-port=8443","--cert-dir=/tmp"],"env":[{"name":"SYSTEM_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}},{"name":"CONFIG_LOGGING_NAME","value":"config-logging"},{"name":"CONFIG_OBSERVABILITY_NAME","value":"config-observability"},{"name":"METRICS_DOMAIN","value":"knative.dev/serving"}],"image":"gcr.io/knative-releases/github.com/knative/serving/cmd/autoscaler@sha256:2c2370df2751741348e1cc456f31425cb2455c377ddb45d3f6c17e743fd63d78","livenessProbe":{"httpGet":{"httpHeaders":[{"name":"k-kubelet-probe","value":"autoscaler"}],"path":"/healthz","port":8080}},"name":"autoscaler","ports":[{"containerPort":8080,"name":"websocket"},{"containerPort":9090,"name":"metrics"},{"containerPort":8443,"name":"custom-metrics"}],"readinessProbe":{"httpGet":{"httpHeaders":[{"name":"k-kubelet-probe","value":"autoscaler"}],"path":"/healthz","port":8080}},"resources":{"limits":{"cpu":"300m","memory":"400Mi"},"requests":{"cpu":"30m","memory":"40Mi"}},"securityContext":{"allowPrivilegeEscalation":false},"volumeMounts":[{"mountPath":"/etc/config-autoscaler","name":"config-autoscaler"},{"mountPath":"/etc/config-logging","name":"config-logging"},{"mountPath":"/etc/config-observability","name":"config-observability"}]}],"serviceAccountName":"controller","volumes":[{"configMap":{"name":"config-autoscaler"},"name":"config-autoscaler"},{"configMap":{"name":"config-logging"},"name":"config-logging"},{"configMap":{"name":"config-observability"},"name":"config-observability"}]}}}}
    labels:
      serving.knative.dev/release: v0.7.0
    name: autoscaler
    namespace: knative-serving
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: autoscaler
    template:
      metadata:
        annotations:
          cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
          sidecar.istio.io/inject: "true"
        labels:
          app: autoscaler
          serving.knative.dev/release: v0.7.0
      spec:
        containers:
        - args:
          - --secure-port=8443
          - --cert-dir=/tmp
          env:
          - name: SYSTEM_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: CONFIG_LOGGING_NAME
            value: config-logging
          - name: CONFIG_OBSERVABILITY_NAME
            value: config-observability
          - name: METRICS_DOMAIN
            value: knative.dev/serving
          image: gcr.io/knative-releases/github.com/knative/serving/cmd/autoscaler@sha256:2c2370df2751741348e1cc456f31425cb2455c377ddb45d3f6c17e743fd63d78
          livenessProbe:
            httpGet:
              httpHeaders:
              - name: k-kubelet-probe
                value: autoscaler
              path: /healthz
              port: 8080
          name: autoscaler
          ports:
          - containerPort: 8080
            name: websocket
          - containerPort: 9090
            name: metrics
          - containerPort: 8443
            name: custom-metrics
          readinessProbe:
            httpGet:
              httpHeaders:
              - name: k-kubelet-probe
                value: autoscaler
              path: /healthz
              port: 8080
          resources:
            limits:
              cpu: 300m
              memory: 400Mi
            requests:
              cpu: 30m
              memory: 40Mi
          securityContext:
            allowPrivilegeEscalation: false
          volumeMounts:
          - mountPath: /etc/config-autoscaler
            name: config-autoscaler
          - mountPath: /etc/config-logging
            name: config-logging
          - mountPath: /etc/config-observability
            name: config-observability
        serviceAccountName: controller
        volumes:
        - configMap:
            name: config-autoscaler
          name: config-autoscaler
        - configMap:
            name: config-logging
          name: config-logging
        - configMap:
            name: config-observability
          name: config-observability
- apiVersion: v1
  data:
    _example: |
      ################################
      #                              #
      #    EXAMPLE CONFIGURATION     #
      #                              #
      ################################

      # This block is not actually functional configuration,
      # but serves to illustrate the available configuration
      # options and document them in a way that is accessible
      # to users that `kubectl edit` this config map.
      #
      # These sample configuration options may be copied out of
      # this example block and unindented to be in the data block
      # to actually change the configuration.

      # The Revision ContainerConcurrency field specifies the maximum number
      # of requests the Container can handle at once. Container concurrency
      # target percentage is how much of that maximum to use in a stable
      # state. E.g. if a Revision specifies ContainerConcurrency of 10, then
      # the Autoscaler will try to maintain 7 concurrent connections per pod
      # on average. A value of 70 is chosen because the Autoscaler panics
      # when concurrency exceeds 2x the desired set point. So we will panic
      # before we reach the limit.
      # For legacy and backwards compatibility reasons, this value also accepts
      # fractional values in (0, 1] interval (i.e. 0.7 ⇒ 70%).
      # Thus minimal percentage value must be greater than 1.0, or it will be
      # treated as a fraction.
      # TODO(#2016): Set to 70%.
      container-concurrency-target-percentage: "100"

      # The container concurrency target default is what the Autoscaler will
      # try to maintain when the Revision specifies unlimited concurrency.
      # Even when specifying unlimited concurrency, the autoscaler will
      # horizontally scale the application based on this target concurrency.
      #
      # A value of 100 is chosen because it's enough to allow vertical pod
      # autoscaling to tune resource requests. E.g. maintaining 1 concurrent
      # "hello world" request doesn't consume enough resources to allow VPA
      # to achieve efficient resource usage (VPA CPU minimum is 300m).
      container-concurrency-target-default: "100"

      # When operating in a stable mode, the autoscaler operates on the
      # average concurrency over the stable window.
      stable-window: "60s"

      # When observed average concurrency during the panic window reaches
      # panic-threshold-percentage the target concurrency, the autoscaler
      # enters panic mode. When operating in panic mode, the autoscaler
      # scales on the average concurrency over the panic window which is
      # panic-window-percentage of the stable-window.
      panic-window-percentage: "10.0"

      # Absolute panic window duration.
      # Deprecated in favor of panic-window-percentage.
      # Existing revisions will continue to scale based on panic-window
      # but new revisions will default to panic-window-percentage.
      panic-window: "6s"

      # The percentage of the container concurrency target at which to
      # enter panic mode when reached within the panic window.
      panic-threshold-percentage: "200.0"

      # Max scale up rate limits the rate at which the autoscaler will
      # increase pod count. It is the maximum ratio of desired pods versus
      # observed pods.
      max-scale-up-rate: "10"

      # Scale to zero feature flag
      enable-scale-to-zero: "true"

      # Tick interval is the time between autoscaling calculations.
      tick-interval: "2s"

      # Dynamic parameters (take effect when config map is updated):

      # Scale to zero grace period is the time an inactive revision is left
      # running before it is scaled to zero (min: 30s).
      scale-to-zero-grace-period: "30s"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"_example":"################################\n#                              #\n#    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\n# This block is not actually functional configuration,\n# but serves to illustrate the available configuration\n# options and document them in a way that is accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample configuration options may be copied out of\n# this example block and unindented to be in the data block\n# to actually change the configuration.\n\n# The Revision ContainerConcurrency field specifies the maximum number\n# of requests the Container can handle at once. Container concurrency\n# target percentage is how much of that maximum to use in a stable\n# state. E.g. if a Revision specifies ContainerConcurrency of 10, then\n# the Autoscaler will try to maintain 7 concurrent connections per pod\n# on average. A value of 70 is chosen because the Autoscaler panics\n# when concurrency exceeds 2x the desired set point. So we will panic\n# before we reach the limit.\n# For legacy and backwards compatibility reasons, this value also accepts\n# fractional values in (0, 1] interval (i.e. 0.7 ⇒ 70%).\n# Thus minimal percentage value must be greater than 1.0, or it will be\n# treated as a fraction.\n# TODO(#2016): Set to 70%.\ncontainer-concurrency-target-percentage: \"100\"\n\n# The container concurrency target default is what the Autoscaler will\n# try to maintain when the Revision specifies unlimited concurrency.\n# Even when specifying unlimited concurrency, the autoscaler will\n# horizontally scale the application based on this target concurrency.\n#\n# A value of 100 is chosen because it's enough to allow vertical pod\n# autoscaling to tune resource requests. E.g. maintaining 1 concurrent\n# \"hello world\" request doesn't consume enough resources to allow VPA\n# to achieve efficient resource usage (VPA CPU minimum is 300m).\ncontainer-concurrency-target-default: \"100\"\n\n# When operating in a stable mode, the autoscaler operates on the\n# average concurrency over the stable window.\nstable-window: \"60s\"\n\n# When observed average concurrency during the panic window reaches\n# panic-threshold-percentage the target concurrency, the autoscaler\n# enters panic mode. When operating in panic mode, the autoscaler\n# scales on the average concurrency over the panic window which is\n# panic-window-percentage of the stable-window.\npanic-window-percentage: \"10.0\"\n\n# Absolute panic window duration.\n# Deprecated in favor of panic-window-percentage.\n# Existing revisions will continue to scale based on panic-window\n# but new revisions will default to panic-window-percentage.\npanic-window: \"6s\"\n\n# The percentage of the container concurrency target at which to\n# enter panic mode when reached within the panic window.\npanic-threshold-percentage: \"200.0\"\n\n# Max scale up rate limits the rate at which the autoscaler will\n# increase pod count. It is the maximum ratio of desired pods versus\n# observed pods.\nmax-scale-up-rate: \"10\"\n\n# Scale to zero feature flag\nenable-scale-to-zero: \"true\"\n\n# Tick interval is the time between autoscaling calculations.\ntick-interval: \"2s\"\n\n# Dynamic parameters (take effect when config map is updated):\n\n# Scale to zero grace period is the time an inactive revision is left\n# running before it is scaled to zero (min: 30s).\nscale-to-zero-grace-period: \"30s\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"serving.knative.dev/release":"v0.7.0"},"name":"config-autoscaler","namespace":"knative-serving"}}
    labels:
      serving.knative.dev/release: v0.7.0
    name: config-autoscaler
    namespace: knative-serving
- apiVersion: v1
  data:
    _example: |
      ################################
      #                              #
      #    EXAMPLE CONFIGURATION     #
      #                              #
      ################################

      # This block is not actually functional configuration,
      # but serves to illustrate the available configuration
      # options and document them in a way that is accessible
      # to users that `kubectl edit` this config map.
      #
      # These sample configuration options may be copied out of
      # this block and unindented to actually change the configuration.

      # IssuerRef is a reference to the issuer for this certificate.
      # IssuerRef should be either `ClusterIssuer` or `Issuer`.
      # Please refer `IssuerRef` in https://github.com/jetstack/cert-manager/blob/master/pkg/apis/certmanager/v1alpha1/types_certificate.go
      # for more details about IssuerRef configuration.
      issuerRef: |
        kind: ClusterIssuer
        name: letsencrypt-issuer

      # solverConfig defines the configuration for the ACME certificate provider.
      # The solverConfig should be either dns01 or http01.
      # Please refer `SolverConfig` in https://github.com/jetstack/cert-manager/blob/master/pkg/apis/certmanager/v1alpha1/types_certificate.go
      # for more details about ACME configuration.
      solverConfig: |
        dns01:
          provider: cloud-dns-provider
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"_example":"################################\n#                              #\n#    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\n# This block is not actually functional configuration,\n# but serves to illustrate the available configuration\n# options and document them in a way that is accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample configuration options may be copied out of\n# this block and unindented to actually change the configuration.\n\n# IssuerRef is a reference to the issuer for this certificate.\n# IssuerRef should be either `ClusterIssuer` or `Issuer`.\n# Please refer `IssuerRef` in https://github.com/jetstack/cert-manager/blob/master/pkg/apis/certmanager/v1alpha1/types_certificate.go\n# for more details about IssuerRef configuration.\nissuerRef: |\n  kind: ClusterIssuer\n  name: letsencrypt-issuer\n\n# solverConfig defines the configuration for the ACME certificate provider.\n# The solverConfig should be either dns01 or http01.\n# Please refer `SolverConfig` in https://github.com/jetstack/cert-manager/blob/master/pkg/apis/certmanager/v1alpha1/types_certificate.go\n# for more details about ACME configuration.\nsolverConfig: |\n  dns01:\n    provider: cloud-dns-provider\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"networking.knative.dev/certificate-provider":"cert-manager","serving.knative.dev/release":"v0.7.0"},"name":"config-certmanager","namespace":"knative-serving"}}
    labels:
      networking.knative.dev/certificate-provider: cert-manager
      serving.knative.dev/release: v0.7.0
    name: config-certmanager
    namespace: knative-serving
- apiVersion: v1
  data:
    _example: |
      ################################
      #                              #
      #    EXAMPLE CONFIGURATION     #
      #                              #
      ################################

      # This block is not actually functional configuration,
      # but serves to illustrate the available configuration
      # options and document them in a way that is accessible
      # to users that `kubectl edit` this config map.
      #
      # These sample configuration options may be copied out of
      # this example block and unindented to be in the data block
      # to actually change the configuration.

      # revision-timeout-seconds contains the default number of
      # seconds to use for the revision's per-request timeout, if
      # none is specified.
      revision-timeout-seconds: "300"  # 5 minutes

      # max-revision-timeout-seconds contains the maximum number of
      # seconds that can be used for revision-timeout-seconds.
      # This value must be greater than or equal to revision-timeout-seconds.
      # If omitted, the system default is used (600 seconds).
      max-revision-timeout-seconds: "600"  # 10 minutes

      # revision-cpu-request contains the cpu allocation to assign
      # to revisions by default.  If omitted, no value is specified
      # and the system default is used.
      revision-cpu-request: "400m"  # 0.4 of a CPU (aka 400 milli-CPU)

      # revision-memory-request contains the memory allocation to assign
      # to revisions by default.  If omitted, no value is specified
      # and the system default is used.
      revision-memory-request: "100M"  # 100 megabytes of memory

      # revision-cpu-limit contains the cpu allocation to limit
      # revisions to by default.  If omitted, no value is specified
      # and the system default is used.
      revision-cpu-limit: "1000m"  # 1 CPU (aka 1000 milli-CPU)

      # revision-memory-limit contains the memory allocation to limit
      # revisions to by default.  If omitted, no value is specified
      # and the system default is used.
      revision-memory-limit: "200M"  # 200 megabytes of memory

      # container-name-template contains a template for the default
      # container name, if none is specified.  This field supports
      # Go templating and is supplied with the ObjectMeta of the
      # enclosing Service or Configuration, so values such as
      # {{.Name}} are also valid.
      container-name-template: "user-container"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"_example":"################################\n#                              #\n#    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\n# This block is not actually functional configuration,\n# but serves to illustrate the available configuration\n# options and document them in a way that is accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample configuration options may be copied out of\n# this example block and unindented to be in the data block\n# to actually change the configuration.\n\n# revision-timeout-seconds contains the default number of\n# seconds to use for the revision's per-request timeout, if\n# none is specified.\nrevision-timeout-seconds: \"300\"  # 5 minutes\n\n# max-revision-timeout-seconds contains the maximum number of\n# seconds that can be used for revision-timeout-seconds.\n# This value must be greater than or equal to revision-timeout-seconds.\n# If omitted, the system default is used (600 seconds).\nmax-revision-timeout-seconds: \"600\"  # 10 minutes\n\n# revision-cpu-request contains the cpu allocation to assign\n# to revisions by default.  If omitted, no value is specified\n# and the system default is used.\nrevision-cpu-request: \"400m\"  # 0.4 of a CPU (aka 400 milli-CPU)\n\n# revision-memory-request contains the memory allocation to assign\n# to revisions by default.  If omitted, no value is specified\n# and the system default is used.\nrevision-memory-request: \"100M\"  # 100 megabytes of memory\n\n# revision-cpu-limit contains the cpu allocation to limit\n# revisions to by default.  If omitted, no value is specified\n# and the system default is used.\nrevision-cpu-limit: \"1000m\"  # 1 CPU (aka 1000 milli-CPU)\n\n# revision-memory-limit contains the memory allocation to limit\n# revisions to by default.  If omitted, no value is specified\n# and the system default is used.\nrevision-memory-limit: \"200M\"  # 200 megabytes of memory\n\n# container-name-template contains a template for the default\n# container name, if none is specified.  This field supports\n# Go templating and is supplied with the ObjectMeta of the\n# enclosing Service or Configuration, so values such as\n# {{.Name}} are also valid.\ncontainer-name-template: \"user-container\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"serving.knative.dev/release":"v0.7.0"},"name":"config-defaults","namespace":"knative-serving"}}
    labels:
      serving.knative.dev/release: v0.7.0
    name: config-defaults
    namespace: knative-serving
- apiVersion: v1
  data:
    _example: |
      ################################
      #                              #
      #    EXAMPLE CONFIGURATION     #
      #                              #
      ################################

      # This block is not actually functional configuration,
      # but serves to illustrate the available configuration
      # options and document them in a way that is accessible
      # to users that `kubectl edit` this config map.
      #
      # These sample configuration options may be copied out of
      # this example block and unindented to be in the data block
      # to actually change the configuration.

      # List of repositories for which tag to digest resolving should be skipped
      registriesSkippingTagResolving: "ko.local,dev.local"
    queueSidecarImage: gcr.io/knative-releases/github.com/knative/serving/cmd/queue@sha256:e007c0a78c541600466f88954deee65c517246a23345bfba45a7f212d09b8f3b
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"_example":"################################\n#                              #\n#    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\n# This block is not actually functional configuration,\n# but serves to illustrate the available configuration\n# options and document them in a way that is accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample configuration options may be copied out of\n# this example block and unindented to be in the data block\n# to actually change the configuration.\n\n# List of repositories for which tag to digest resolving should be skipped\nregistriesSkippingTagResolving: \"ko.local,dev.local\"\n","queueSidecarImage":"gcr.io/knative-releases/github.com/knative/serving/cmd/queue@sha256:e007c0a78c541600466f88954deee65c517246a23345bfba45a7f212d09b8f3b"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"serving.knative.dev/release":"v0.7.0"},"name":"config-deployment","namespace":"knative-serving"}}
    labels:
      serving.knative.dev/release: v0.7.0
    name: config-deployment
    namespace: knative-serving
- apiVersion: v1
  data:
    _example: |
      ################################
      #                              #
      #    EXAMPLE CONFIGURATION     #
      #                              #
      ################################

      # This block is not actually functional configuration,
      # but serves to illustrate the available configuration
      # options and document them in a way that is accessible
      # to users that `kubectl edit` this config map.
      #
      # These sample configuration options may be copied out of
      # this example block and unindented to be in the data block
      # to actually change the configuration.

      # Default value for domain.
      # Although it will match all routes, it is the least-specific rule so it
      # will only be used if no other domain matches.
      example.com: |

      # These are example settings of domain.
      # example.org will be used for routes having app=nonprofit.
      example.org: |
        selector:
          app: nonprofit

      # Routes having domain suffix of 'svc.cluster.local' will not be exposed
      # through Ingress. You can define your own label selector to assign that
      # domain suffix to your Route here, or you can set the label
      #    "serving.knative.dev/visibility=cluster-local"
      # to achieve the same effect.  This shows how to make routes having
      # the label app=secret only exposed to the local cluster.
      svc.cluster.local: |
        selector:
          app: secret
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"_example":"################################\n#                              #\n#    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\n# This block is not actually functional configuration,\n# but serves to illustrate the available configuration\n# options and document them in a way that is accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample configuration options may be copied out of\n# this example block and unindented to be in the data block\n# to actually change the configuration.\n\n# Default value for domain.\n# Although it will match all routes, it is the least-specific rule so it\n# will only be used if no other domain matches.\nexample.com: |\n\n# These are example settings of domain.\n# example.org will be used for routes having app=nonprofit.\nexample.org: |\n  selector:\n    app: nonprofit\n\n# Routes having domain suffix of 'svc.cluster.local' will not be exposed\n# through Ingress. You can define your own label selector to assign that\n# domain suffix to your Route here, or you can set the label\n#    \"serving.knative.dev/visibility=cluster-local\"\n# to achieve the same effect.  This shows how to make routes having\n# the label app=secret only exposed to the local cluster.\nsvc.cluster.local: |\n  selector:\n    app: secret\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"serving.knative.dev/release":"v0.7.0"},"name":"config-domain","namespace":"knative-serving"}}
    labels:
      serving.knative.dev/release: v0.7.0
    name: config-domain
    namespace: knative-serving
- apiVersion: v1
  data:
    _example: |
      ################################
      #                              #
      #    EXAMPLE CONFIGURATION     #
      #                              #
      ################################

      # This block is not actually functional configuration,
      # but serves to illustrate the available configuration
      # options and document them in a way that is accessible
      # to users that `kubectl edit` this config map.
      #
      # These sample configuration options may be copied out of
      # this example block and unindented to be in the data block
      # to actually change the configuration.

      # Delay after revision creation before considering it for GC
      stale-revision-create-delay: "24h"

      # Duration since a route has been pointed at a revision before it should be GC'd
      # This minus lastpinned-debounce be longer than the controller resync period (10 hours)
      stale-revision-timeout: "15h"

      # Minimum number of generations of revisions to keep before considering for GC
      stale-revision-minimum-generations: "1"

      # To avoid constant updates, we allow an existing annotation to be stale by this
      # amount before we update the timestamp
      stale-revision-lastpinned-debounce: "5h"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"_example":"################################\n#                              #\n#    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\n# This block is not actually functional configuration,\n# but serves to illustrate the available configuration\n# options and document them in a way that is accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample configuration options may be copied out of\n# this example block and unindented to be in the data block\n# to actually change the configuration.\n\n# Delay after revision creation before considering it for GC\nstale-revision-create-delay: \"24h\"\n\n# Duration since a route has been pointed at a revision before it should be GC'd\n# This minus lastpinned-debounce be longer than the controller resync period (10 hours)\nstale-revision-timeout: \"15h\"\n\n# Minimum number of generations of revisions to keep before considering for GC\nstale-revision-minimum-generations: \"1\"\n\n# To avoid constant updates, we allow an existing annotation to be stale by this\n# amount before we update the timestamp\nstale-revision-lastpinned-debounce: \"5h\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"serving.knative.dev/release":"v0.7.0"},"name":"config-gc","namespace":"knative-serving"}}
    labels:
      serving.knative.dev/release: v0.7.0
    name: config-gc
    namespace: knative-serving
- apiVersion: v1
  data:
    _example: |
      ################################
      #                              #
      #    EXAMPLE CONFIGURATION     #
      #                              #
      ################################

      # This block is not actually functional configuration,
      # but serves to illustrate the available configuration
      # options and document them in a way that is accessible
      # to users that `kubectl edit` this config map.
      #
      # These sample configuration options may be copied out of
      # this example block and unindented to be in the data block
      # to actually change the configuration.

      # Default Knative Gateway after v0.3. It points to the Istio
      # standard istio-ingressgateway, instead of a custom one that we
      # used pre-0.3.
      gateway.knative-ingress-gateway: "istio-ingressgateway.istio-system.svc.cluster.local"

      # A cluster local gateway to allow pods outside of the mesh to access
      # Services and Routes not exposing through an ingress.  If the users
      # do have a service mesh setup, this isn't required and can be removed.
      #
      # An example use case is when users want to use Istio without any
      # sidecar injection (like Knative's istio-lean.yaml).  Since every pod
      # is outside of the service mesh in that case, a cluster-local  service
      # will need to be exposed to a cluster-local gateway to be accessible.
      local-gateway.cluster-local-gateway: "cluster-local-gateway.istio-system.svc.cluster.local"

      # To use only Istio service mesh and no cluster-local-gateway, replace
      # all local-gateway.* entries the following entry.
      local-gateway.mesh: "mesh"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"_example":"################################\n#                              #\n#    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\n# This block is not actually functional configuration,\n# but serves to illustrate the available configuration\n# options and document them in a way that is accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample configuration options may be copied out of\n# this example block and unindented to be in the data block\n# to actually change the configuration.\n\n# Default Knative Gateway after v0.3. It points to the Istio\n# standard istio-ingressgateway, instead of a custom one that we\n# used pre-0.3.\ngateway.knative-ingress-gateway: \"istio-ingressgateway.istio-system.svc.cluster.local\"\n\n# A cluster local gateway to allow pods outside of the mesh to access\n# Services and Routes not exposing through an ingress.  If the users\n# do have a service mesh setup, this isn't required and can be removed.\n#\n# An example use case is when users want to use Istio without any\n# sidecar injection (like Knative's istio-lean.yaml).  Since every pod\n# is outside of the service mesh in that case, a cluster-local  service\n# will need to be exposed to a cluster-local gateway to be accessible.\nlocal-gateway.cluster-local-gateway: \"cluster-local-gateway.istio-system.svc.cluster.local\"\n\n# To use only Istio service mesh and no cluster-local-gateway, replace\n# all local-gateway.* entries the following entry.\nlocal-gateway.mesh: \"mesh\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"networking.knative.dev/ingress-provider":"istio","serving.knative.dev/release":"v0.7.0"},"name":"config-istio","namespace":"knative-serving"}}
    labels:
      networking.knative.dev/ingress-provider: istio
      serving.knative.dev/release: v0.7.0
    name: config-istio
    namespace: knative-serving
- apiVersion: v1
  data:
    _example: |
      ################################
      #                              #
      #    EXAMPLE CONFIGURATION     #
      #                              #
      ################################

      # This block is not actually functional configuration,
      # but serves to illustrate the available configuration
      # options and document them in a way that is accessible
      # to users that `kubectl edit` this config map.
      #
      # These sample configuration options may be copied out of
      # this example block and unindented to be in the data block
      # to actually change the configuration.

      # Common configuration for all Knative codebase
      zap-logger-config: |
        {
          "level": "info",
          "development": false,
          "outputPaths": ["stdout"],
          "errorOutputPaths": ["stderr"],
          "encoding": "json",
          "encoderConfig": {
            "timeKey": "ts",
            "levelKey": "level",
            "nameKey": "logger",
            "callerKey": "caller",
            "messageKey": "msg",
            "stacktraceKey": "stacktrace",
            "lineEnding": "",
            "levelEncoder": "",
            "timeEncoder": "iso8601",
            "durationEncoder": "",
            "callerEncoder": ""
          }
        }

      # Log level overrides
      # For all components except the autoscaler and queue proxy,
      # changes are be picked up immediately.
      # For autoscaler and queue proxy, changes require recreation of the pods.
      loglevel.controller: "info"
      loglevel.autoscaler: "info"
      loglevel.queueproxy: "info"
      loglevel.webhook: "info"
      loglevel.activator: "info"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"_example":"################################\n#                              #\n#    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\n# This block is not actually functional configuration,\n# but serves to illustrate the available configuration\n# options and document them in a way that is accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample configuration options may be copied out of\n# this example block and unindented to be in the data block\n# to actually change the configuration.\n\n# Common configuration for all Knative codebase\nzap-logger-config: |\n  {\n    \"level\": \"info\",\n    \"development\": false,\n    \"outputPaths\": [\"stdout\"],\n    \"errorOutputPaths\": [\"stderr\"],\n    \"encoding\": \"json\",\n    \"encoderConfig\": {\n      \"timeKey\": \"ts\",\n      \"levelKey\": \"level\",\n      \"nameKey\": \"logger\",\n      \"callerKey\": \"caller\",\n      \"messageKey\": \"msg\",\n      \"stacktraceKey\": \"stacktrace\",\n      \"lineEnding\": \"\",\n      \"levelEncoder\": \"\",\n      \"timeEncoder\": \"iso8601\",\n      \"durationEncoder\": \"\",\n      \"callerEncoder\": \"\"\n    }\n  }\n\n# Log level overrides\n# For all components except the autoscaler and queue proxy,\n# changes are be picked up immediately.\n# For autoscaler and queue proxy, changes require recreation of the pods.\nloglevel.controller: \"info\"\nloglevel.autoscaler: \"info\"\nloglevel.queueproxy: \"info\"\nloglevel.webhook: \"info\"\nloglevel.activator: \"info\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"serving.knative.dev/release":"v0.7.0"},"name":"config-logging","namespace":"knative-serving"}}
    labels:
      serving.knative.dev/release: v0.7.0
    name: config-logging
    namespace: knative-serving
- apiVersion: v1
  data:
    _example: |
      ################################
      #                              #
      #    EXAMPLE CONFIGURATION     #
      #                              #
      ################################

      # This block is not actually functional configuration,
      # but serves to illustrate the available configuration
      # options and document them in a way that is accessible
      # to users that `kubectl edit` this config map.
      #
      # These sample configuration options may be copied out of
      # this example block and unindented to be in the data block
      # to actually change the configuration.

      # istio.sidecar.includeOutboundIPRanges specifies the IP ranges that Istio sidecar
      # will intercept.
      #
      # Replace this with the IP ranges of your cluster (see below for some examples).
      # Separate multiple entries with a comma.
      # Example: "10.4.0.0/14,10.7.240.0/20"
      #
      # If set to "*" Istio will intercept all traffic within
      # the cluster as well as traffic that is going outside the cluster.
      # Traffic going outside the cluster will be blocked unless
      # necessary egress rules are created.
      #
      # If omitted or set to "", value of global.proxy.includeIPRanges
      # provided at Istio deployment time is used. In default Knative serving
      # deployment, global.proxy.includeIPRanges value is set to "*".
      #
      # If an invalid value is passed, "" is used instead.
      #
      # If valid set of IP address ranges are put into this value,
      # Istio will no longer intercept traffic going to IP addresses
      # outside the provided ranges and there is no need to specify
      # egress rules.
      #
      # To determine the IP ranges of your cluster:
      #   IBM Cloud Private: cat cluster/config.yaml | grep service_cluster_ip_range
      #   IBM Cloud Kubernetes Service: "172.30.0.0/16,172.20.0.0/16,10.10.10.0/24"
      #   Google Container Engine (GKE): gcloud container clusters describe XXXXXXX --zone=XXXXXX | grep -e clusterIpv4Cidr -e servicesIpv4Cidr
      #   Azure Kubernetes Service (AKS): "10.0.0.0/16"
      #   Azure Container Service (ACS; deprecated): "10.244.0.0/16,10.240.0.0/16"
      #   Azure Container Service Engine (ACS-Engine; OSS): Configurable, but defaults to "10.0.0.0/16"
      #   Minikube: "10.0.0.1/24"
      #
      # For more information, visit
      # https://istio.io/docs/tasks/traffic-management/egress/
      #
      istio.sidecar.includeOutboundIPRanges: "*"

      # clusteringress.class specifies the default cluster ingress class
      # to use when not dictated by Route annotation.
      #
      # If not specified, will use the Istio ingress.
      #
      # Note that changing the ClusterIngress class of an existing Route
      # will result in undefined behavior.  Therefore it is best to only
      # update this value during the setup of Knative, to avoid getting
      # undefined behavior.
      clusteringress.class: "istio.ingress.networking.knative.dev"

      # domainTemplate specifies the golang text template string to use
      # when constructing the Knative service's DNS name. The default
      # value is "{{.Name}}.{{.Namespace}}.{{.Domain}}". And those three
      # values (Name, Namespace, Domain) are the only variables defined.
      #
      # Changing this value might be necessary when the extra levels in
      # the domain name generated is problematic for wildcard certificates
      # that only support a single level of domain name added to the
      # certificate's domain. In those cases you might consider using a value
      # of "{{.Name}}-{{.Namespace}}.{{.Domain}}", or removing the Namespace
      # entirely from the template. When choosing a new value be thoughtful
      # of the potential for conflicts - for example, when users choose to use
      # characters such as `-` in their service, or namespace, names.
      # {{.Annotations}} can be used for any customization in the go template if needed.
      # We strongly recommend keeping namespace part of the template to avoid domain name clashes
      # Example '{{.Name}}-{{.Namespace}}.{{ index .Annotations "sub"}}.{{.Domain}}'
      # and you have an annotation {"sub":"foo"}, then the generated template would be {Name}-{Namespace}.foo.{Domain}
      domainTemplate: "{{.Name}}.{{.Namespace}}.{{.Domain}}"

      # tagTemplate specifies the golang text template string to use
      # when constructing the DNS name for "tags" within the traffic blocks
      # of Routes and Configuration.  This is used in conjunction with the
      # domainTemplate above to determine the full URL for the tag.
      tagTemplate: "{{.Name}}-{{.Tag}}"

      # Controls whether TLS certificates are automatically provisioned and
      # installed in the Knative ingress to terminate external TLS connection.
      # 1. Enabled: enabling auto-TLS feature.
      # 2. Disabled: disabling auto-TLS feature.
      autoTLS: "Disabled"

      # Controls the behavior of the HTTP endpoint for the Knative ingress.
      # It requires autoTLS to be enabled.
      # 1. Enabled: The Knative ingress will be able to serve HTTP connection.
      # 2. Disabled: The Knative ingress ter will reject HTTP traffic.
      # 3. Redirected: The Knative ingress will send a 302 redirect for all
      # http connections, asking the clients to use HTTPS
      httpProtocol: "Enabled"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"_example":"################################\n#                              #\n#    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\n# This block is not actually functional configuration,\n# but serves to illustrate the available configuration\n# options and document them in a way that is accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample configuration options may be copied out of\n# this example block and unindented to be in the data block\n# to actually change the configuration.\n\n# istio.sidecar.includeOutboundIPRanges specifies the IP ranges that Istio sidecar\n# will intercept.\n#\n# Replace this with the IP ranges of your cluster (see below for some examples).\n# Separate multiple entries with a comma.\n# Example: \"10.4.0.0/14,10.7.240.0/20\"\n#\n# If set to \"*\" Istio will intercept all traffic within\n# the cluster as well as traffic that is going outside the cluster.\n# Traffic going outside the cluster will be blocked unless\n# necessary egress rules are created.\n#\n# If omitted or set to \"\", value of global.proxy.includeIPRanges\n# provided at Istio deployment time is used. In default Knative serving\n# deployment, global.proxy.includeIPRanges value is set to \"*\".\n#\n# If an invalid value is passed, \"\" is used instead.\n#\n# If valid set of IP address ranges are put into this value,\n# Istio will no longer intercept traffic going to IP addresses\n# outside the provided ranges and there is no need to specify\n# egress rules.\n#\n# To determine the IP ranges of your cluster:\n#   IBM Cloud Private: cat cluster/config.yaml | grep service_cluster_ip_range\n#   IBM Cloud Kubernetes Service: \"172.30.0.0/16,172.20.0.0/16,10.10.10.0/24\"\n#   Google Container Engine (GKE): gcloud container clusters describe XXXXXXX --zone=XXXXXX | grep -e clusterIpv4Cidr -e servicesIpv4Cidr\n#   Azure Kubernetes Service (AKS): \"10.0.0.0/16\"\n#   Azure Container Service (ACS; deprecated): \"10.244.0.0/16,10.240.0.0/16\"\n#   Azure Container Service Engine (ACS-Engine; OSS): Configurable, but defaults to \"10.0.0.0/16\"\n#   Minikube: \"10.0.0.1/24\"\n#\n# For more information, visit\n# https://istio.io/docs/tasks/traffic-management/egress/\n#\nistio.sidecar.includeOutboundIPRanges: \"*\"\n\n# clusteringress.class specifies the default cluster ingress class\n# to use when not dictated by Route annotation.\n#\n# If not specified, will use the Istio ingress.\n#\n# Note that changing the ClusterIngress class of an existing Route\n# will result in undefined behavior.  Therefore it is best to only\n# update this value during the setup of Knative, to avoid getting\n# undefined behavior.\nclusteringress.class: \"istio.ingress.networking.knative.dev\"\n\n# domainTemplate specifies the golang text template string to use\n# when constructing the Knative service's DNS name. The default\n# value is \"{{.Name}}.{{.Namespace}}.{{.Domain}}\". And those three\n# values (Name, Namespace, Domain) are the only variables defined.\n#\n# Changing this value might be necessary when the extra levels in\n# the domain name generated is problematic for wildcard certificates\n# that only support a single level of domain name added to the\n# certificate's domain. In those cases you might consider using a value\n# of \"{{.Name}}-{{.Namespace}}.{{.Domain}}\", or removing the Namespace\n# entirely from the template. When choosing a new value be thoughtful\n# of the potential for conflicts - for example, when users choose to use\n# characters such as `-` in their service, or namespace, names.\n# {{.Annotations}} can be used for any customization in the go template if needed.\n# We strongly recommend keeping namespace part of the template to avoid domain name clashes\n# Example '{{.Name}}-{{.Namespace}}.{{ index .Annotations \"sub\"}}.{{.Domain}}'\n# and you have an annotation {\"sub\":\"foo\"}, then the generated template would be {Name}-{Namespace}.foo.{Domain}\ndomainTemplate: \"{{.Name}}.{{.Namespace}}.{{.Domain}}\"\n\n# tagTemplate specifies the golang text template string to use\n# when constructing the DNS name for \"tags\" within the traffic blocks\n# of Routes and Configuration.  This is used in conjunction with the\n# domainTemplate above to determine the full URL for the tag.\ntagTemplate: \"{{.Name}}-{{.Tag}}\"\n\n# Controls whether TLS certificates are automatically provisioned and\n# installed in the Knative ingress to terminate external TLS connection.\n# 1. Enabled: enabling auto-TLS feature.\n# 2. Disabled: disabling auto-TLS feature.\nautoTLS: \"Disabled\"\n\n# Controls the behavior of the HTTP endpoint for the Knative ingress.\n# It requires autoTLS to be enabled.\n# 1. Enabled: The Knative ingress will be able to serve HTTP connection.\n# 2. Disabled: The Knative ingress ter will reject HTTP traffic.\n# 3. Redirected: The Knative ingress will send a 302 redirect for all\n# http connections, asking the clients to use HTTPS\nhttpProtocol: \"Enabled\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"serving.knative.dev/release":"v0.7.0"},"name":"config-network","namespace":"knative-serving"}}
    labels:
      serving.knative.dev/release: v0.7.0
    name: config-network
    namespace: knative-serving
- apiVersion: v1
  data:
    _example: |
      ################################
      #                              #
      #    EXAMPLE CONFIGURATION     #
      #                              #
      ################################

      # This block is not actually functional configuration,
      # but serves to illustrate the available configuration
      # options and document them in a way that is accessible
      # to users that `kubectl edit` this config map.
      #
      # These sample configuration options may be copied out of
      # this example block and unindented to be in the data block
      # to actually change the configuration.

      # logging.enable-var-log-collection defaults to false.
      # The fluentd daemon set will be set up to collect /var/log if
      # this flag is true.
      logging.enable-var-log-collection: false

      # logging.revision-url-template provides a template to use for producing the
      # logging URL that is injected into the status of each Revision.
      # This value is what you might use the the Knative monitoring bundle, and provides
      # access to Kibana after setting up kubectl proxy.
      logging.revision-url-template: |
        http://localhost:8001/api/v1/namespaces/knative-monitoring/services/kibana-logging/proxy/app/kibana#/discover?_a=(query:(match:(kubernetes.labels.knative-dev%2FrevisionUID:(query:'${REVISION_UID}',type:phrase))))

      # If non-empty, this enables queue proxy writing request logs to stdout.
      # The value determines the shape of the request logs and it must be a valid go text/template.
      # It is important to keep this as a single line. Multiple lines are parsed as separate entities
      # by most collection agents and will split the request logs into multiple records.
      #
      # The following fields and functions are available to the template:
      #
      # Request: An http.Request (see https://golang.org/pkg/net/http/#Request)
      # representing an HTTP request received by the server.
      #
      # Response:
      # struct {
      #   Code    int       // HTTP status code (see https://www.iana.org/assignments/http-status-codes/http-status-codes.xhtml)
      #   Size    int       // An int representing the size of the response.
      #   Latency float64   // A float64 representing the latency of the response in seconds.
      # }
      #
      # Revision:
      # struct {
      #   Name          string  // Knative revision name
      #   Namespace     string  // Knative revision namespace
      #   Service       string  // Knative service name
      #   Configuration string  // Knative configuration name
      #   PodName       string  // Name of the pod hosting the revision
      #   PodIP         string  // IP of the pod hosting the revision
      # }
      #
      logging.request-log-template: '{"httpRequest": {"requestMethod": "{{.Request.Method}}", "requestUrl": "{{js .Request.RequestURI}}", "requestSize": "{{.Request.ContentLength}}", "status": {{.Response.Code}}, "responseSize": "{{.Response.Size}}", "userAgent": "{{js .Request.UserAgent}}", "remoteIp": "{{js .Request.RemoteAddr}}", "serverIp": "{{.Revision.PodIP}}", "referer": "{{js .Request.Referer}}", "latency": "{{.Response.Latency}}s", "protocol": "{{.Request.Proto}}"}, "traceId": "{{index .Request.Header "X-B3-Traceid"}}"}'

      # metrics.backend-destination field specifies the system metrics destination.
      # It supports either prometheus (the default) or stackdriver.
      # Note: Using stackdriver will incur additional charges
      metrics.backend-destination: prometheus

      # metrics.request-metrics-backend-destination specifies the request metrics
      # destination. If non-empty, it enables queue proxy to send request metrics.
      # Currently supported values: prometheus, stackdriver.
      metrics.request-metrics-backend-destination: prometheus

      # metrics.stackdriver-project-id field specifies the stackdriver project ID. This
      # field is optional. When running on GCE, application default credentials will be
      # used if this field is not provided.
      metrics.stackdriver-project-id: "<your stackdriver project id>"

      # metrics.allow-stackdriver-custom-metrics indicates whether it is allowed to send metrics to
      # Stackdriver using "global" resource type and custom metric type if the
      # metrics are not supported by "knative_revision" resource type. Setting this
      # flag to "true" could cause extra Stackdriver charge.
      # If metrics.backend-destination is not Stackdriver, this is ignored.
      metrics.allow-stackdriver-custom-metrics: "false"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"_example":"################################\n#                              #\n#    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\n# This block is not actually functional configuration,\n# but serves to illustrate the available configuration\n# options and document them in a way that is accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample configuration options may be copied out of\n# this example block and unindented to be in the data block\n# to actually change the configuration.\n\n# logging.enable-var-log-collection defaults to false.\n# The fluentd daemon set will be set up to collect /var/log if\n# this flag is true.\nlogging.enable-var-log-collection: false\n\n# logging.revision-url-template provides a template to use for producing the\n# logging URL that is injected into the status of each Revision.\n# This value is what you might use the the Knative monitoring bundle, and provides\n# access to Kibana after setting up kubectl proxy.\nlogging.revision-url-template: |\n  http://localhost:8001/api/v1/namespaces/knative-monitoring/services/kibana-logging/proxy/app/kibana#/discover?_a=(query:(match:(kubernetes.labels.knative-dev%2FrevisionUID:(query:'${REVISION_UID}',type:phrase))))\n\n# If non-empty, this enables queue proxy writing request logs to stdout.\n# The value determines the shape of the request logs and it must be a valid go text/template.\n# It is important to keep this as a single line. Multiple lines are parsed as separate entities\n# by most collection agents and will split the request logs into multiple records.\n#\n# The following fields and functions are available to the template:\n#\n# Request: An http.Request (see https://golang.org/pkg/net/http/#Request)\n# representing an HTTP request received by the server.\n#\n# Response:\n# struct {\n#   Code    int       // HTTP status code (see https://www.iana.org/assignments/http-status-codes/http-status-codes.xhtml)\n#   Size    int       // An int representing the size of the response.\n#   Latency float64   // A float64 representing the latency of the response in seconds.\n# }\n#\n# Revision:\n# struct {\n#   Name          string  // Knative revision name\n#   Namespace     string  // Knative revision namespace\n#   Service       string  // Knative service name\n#   Configuration string  // Knative configuration name\n#   PodName       string  // Name of the pod hosting the revision\n#   PodIP         string  // IP of the pod hosting the revision\n# }\n#\nlogging.request-log-template: '{\"httpRequest\": {\"requestMethod\": \"{{.Request.Method}}\", \"requestUrl\": \"{{js .Request.RequestURI}}\", \"requestSize\": \"{{.Request.ContentLength}}\", \"status\": {{.Response.Code}}, \"responseSize\": \"{{.Response.Size}}\", \"userAgent\": \"{{js .Request.UserAgent}}\", \"remoteIp\": \"{{js .Request.RemoteAddr}}\", \"serverIp\": \"{{.Revision.PodIP}}\", \"referer\": \"{{js .Request.Referer}}\", \"latency\": \"{{.Response.Latency}}s\", \"protocol\": \"{{.Request.Proto}}\"}, \"traceId\": \"{{index .Request.Header \"X-B3-Traceid\"}}\"}'\n\n# metrics.backend-destination field specifies the system metrics destination.\n# It supports either prometheus (the default) or stackdriver.\n# Note: Using stackdriver will incur additional charges\nmetrics.backend-destination: prometheus\n\n# metrics.request-metrics-backend-destination specifies the request metrics\n# destination. If non-empty, it enables queue proxy to send request metrics.\n# Currently supported values: prometheus, stackdriver.\nmetrics.request-metrics-backend-destination: prometheus\n\n# metrics.stackdriver-project-id field specifies the stackdriver project ID. This\n# field is optional. When running on GCE, application default credentials will be\n# used if this field is not provided.\nmetrics.stackdriver-project-id: \"\u003cyour stackdriver project id\u003e\"\n\n# metrics.allow-stackdriver-custom-metrics indicates whether it is allowed to send metrics to\n# Stackdriver using \"global\" resource type and custom metric type if the\n# metrics are not supported by \"knative_revision\" resource type. Setting this\n# flag to \"true\" could cause extra Stackdriver charge.\n# If metrics.backend-destination is not Stackdriver, this is ignored.\nmetrics.allow-stackdriver-custom-metrics: \"false\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"serving.knative.dev/release":"v0.7.0"},"name":"config-observability","namespace":"knative-serving"}}
    labels:
      serving.knative.dev/release: v0.7.0
    name: config-observability
    namespace: knative-serving
- apiVersion: v1
  data:
    _example: |
      ################################
      #                              #
      #    EXAMPLE CONFIGURATION     #
      #                              #
      ################################

      # This block is not actually functional configuration,
      # but serves to illustrate the available configuration
      # options and document them in a way that is accessible
      # to users that `kubectl edit` this config map.
      #
      # These sample configuration options may be copied out of
      # this example block and unindented to be in the data block
      # to actually change the configuration.
      #
      # If true we enable adding spans within our applications.
      enable: "false"

      # URL to zipkin collector where traces are sent.
      zipkin-endpoint: "http://zipkin.istio-system.svc.cluster.local:9411/api/v2/spans"

      # Enable zipkin debug mode. This allows all spans to be sent to the server
      # bypassing sampling.
      debug: "false"

      # Percentage (0-1) of requests to trace
      sample-rate: "0.1"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"_example":"################################\n#                              #\n#    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\n# This block is not actually functional configuration,\n# but serves to illustrate the available configuration\n# options and document them in a way that is accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample configuration options may be copied out of\n# this example block and unindented to be in the data block\n# to actually change the configuration.\n#\n# If true we enable adding spans within our applications.\nenable: \"false\"\n\n# URL to zipkin collector where traces are sent.\nzipkin-endpoint: \"http://zipkin.istio-system.svc.cluster.local:9411/api/v2/spans\"\n\n# Enable zipkin debug mode. This allows all spans to be sent to the server\n# bypassing sampling.\ndebug: \"false\"\n\n# Percentage (0-1) of requests to trace\nsample-rate: \"0.1\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"serving.knative.dev/release":"v0.7.0"},"name":"config-tracing","namespace":"knative-serving"}}
    labels:
      serving.knative.dev/release: v0.7.0
    name: config-tracing
    namespace: knative-serving
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"serving.knative.dev/release":"v0.7.0"},"name":"controller","namespace":"knative-serving"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"controller"}},"template":{"metadata":{"annotations":{"sidecar.istio.io/inject":"false"},"labels":{"app":"controller","serving.knative.dev/release":"v0.7.0"}},"spec":{"containers":[{"env":[{"name":"SYSTEM_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}},{"name":"CONFIG_LOGGING_NAME","value":"config-logging"},{"name":"CONFIG_OBSERVABILITY_NAME","value":"config-observability"},{"name":"METRICS_DOMAIN","value":"knative.dev/serving"}],"image":"gcr.io/knative-releases/github.com/knative/serving/cmd/controller@sha256:016c95f2d94be89683d1ddb7ea959667fd2d899087a4145a31d26b5d6f0bb38f","name":"controller","ports":[{"containerPort":9090,"name":"metrics"}],"resources":{"limits":{"cpu":"1000m","memory":"1000Mi"},"requests":{"cpu":"100m","memory":"100Mi"}},"securityContext":{"allowPrivilegeEscalation":false},"volumeMounts":[{"mountPath":"/etc/config-logging","name":"config-logging"}]}],"serviceAccountName":"controller","volumes":[{"configMap":{"name":"config-logging"},"name":"config-logging"}]}}}}
    labels:
      serving.knative.dev/release: v0.7.0
    name: controller
    namespace: knative-serving
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: controller
    template:
      metadata:
        annotations:
          sidecar.istio.io/inject: "false"
        labels:
          app: controller
          serving.knative.dev/release: v0.7.0
      spec:
        containers:
        - env:
          - name: SYSTEM_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: CONFIG_LOGGING_NAME
            value: config-logging
          - name: CONFIG_OBSERVABILITY_NAME
            value: config-observability
          - name: METRICS_DOMAIN
            value: knative.dev/serving
          image: gcr.io/knative-releases/github.com/knative/serving/cmd/controller@sha256:016c95f2d94be89683d1ddb7ea959667fd2d899087a4145a31d26b5d6f0bb38f
          name: controller
          ports:
          - containerPort: 9090
            name: metrics
          resources:
            limits:
              cpu: 1000m
              memory: 1000Mi
            requests:
              cpu: 100m
              memory: 100Mi
          securityContext:
            allowPrivilegeEscalation: false
          volumeMounts:
          - mountPath: /etc/config-logging
            name: config-logging
        serviceAccountName: controller
        volumes:
        - configMap:
            name: config-logging
          name: config-logging
- apiVersion: apiregistration.k8s.io/v1beta1
  kind: APIService
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apiregistration.k8s.io/v1beta1","kind":"APIService","metadata":{"annotations":{},"labels":{"autoscaling.knative.dev/metric-provider":"custom-metrics","serving.knative.dev/release":"v0.7.0"},"name":"v1beta1.custom.metrics.k8s.io"},"spec":{"group":"custom.metrics.k8s.io","groupPriorityMinimum":100,"insecureSkipTLSVerify":true,"service":{"name":"autoscaler","namespace":"knative-serving"},"version":"v1beta1","versionPriority":100}}
    labels:
      autoscaling.knative.dev/metric-provider: custom-metrics
      serving.knative.dev/release: v0.7.0
    name: v1beta1.custom.metrics.k8s.io
  spec:
    group: custom.metrics.k8s.io
    groupPriorityMinimum: 100
    insecureSkipTLSVerify: true
    service:
      name: autoscaler
      namespace: knative-serving
    version: v1beta1
    versionPriority: 100
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"networking.knative.dev/certificate-provider":"cert-manager","serving.knative.dev/release":"v0.7.0"},"name":"networking-certmanager","namespace":"knative-serving"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"networking-certmanager"}},"template":{"metadata":{"annotations":{"sidecar.istio.io/inject":"false"},"labels":{"app":"networking-certmanager"}},"spec":{"containers":[{"env":[{"name":"SYSTEM_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}},{"name":"CONFIG_LOGGING_NAME","value":"config-logging"},{"name":"CONFIG_OBSERVABILITY_NAME","value":"config-observability"},{"name":"METRICS_DOMAIN","value":"knative.dev/serving"}],"image":"gcr.io/knative-releases/github.com/knative/serving/cmd/networking/certmanager@sha256:c757629165393f778d5c0e8b611c9c4857b24f0c748d985d3a080d0161a85248","name":"networking-certmanager","ports":[{"containerPort":9090,"name":"metrics"}],"resources":{"limits":{"cpu":"1000m","memory":"1000Mi"},"requests":{"cpu":"100m","memory":"100Mi"}},"securityContext":{"allowPrivilegeEscalation":false},"volumeMounts":[{"mountPath":"/etc/config-logging","name":"config-logging"}]}],"serviceAccountName":"controller","volumes":[{"configMap":{"name":"config-logging"},"name":"config-logging"}]}}}}
    labels:
      networking.knative.dev/certificate-provider: cert-manager
      serving.knative.dev/release: v0.7.0
    name: networking-certmanager
    namespace: knative-serving
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: networking-certmanager
    template:
      metadata:
        annotations:
          sidecar.istio.io/inject: "false"
        labels:
          app: networking-certmanager
      spec:
        containers:
        - env:
          - name: SYSTEM_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: CONFIG_LOGGING_NAME
            value: config-logging
          - name: CONFIG_OBSERVABILITY_NAME
            value: config-observability
          - name: METRICS_DOMAIN
            value: knative.dev/serving
          image: gcr.io/knative-releases/github.com/knative/serving/cmd/networking/certmanager@sha256:c757629165393f778d5c0e8b611c9c4857b24f0c748d985d3a080d0161a85248
          name: networking-certmanager
          ports:
          - containerPort: 9090
            name: metrics
          resources:
            limits:
              cpu: 1000m
              memory: 1000Mi
            requests:
              cpu: 100m
              memory: 100Mi
          securityContext:
            allowPrivilegeEscalation: false
          volumeMounts:
          - mountPath: /etc/config-logging
            name: config-logging
        serviceAccountName: controller
        volumes:
        - configMap:
            name: config-logging
          name: config-logging
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"networking.knative.dev/ingress-provider":"istio","serving.knative.dev/release":"v0.7.0"},"name":"networking-istio","namespace":"knative-serving"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"networking-istio"}},"template":{"metadata":{"annotations":{"sidecar.istio.io/inject":"false"},"labels":{"app":"networking-istio"}},"spec":{"containers":[{"env":[{"name":"SYSTEM_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}},{"name":"CONFIG_LOGGING_NAME","value":"config-logging"},{"name":"CONFIG_OBSERVABILITY_NAME","value":"config-observability"},{"name":"METRICS_DOMAIN","value":"knative.dev/serving"}],"image":"gcr.io/knative-releases/github.com/knative/serving/cmd/networking/istio@sha256:bb4407e4714511cd9429e86536c283265629a2c11c80633d91c0f798c494a16f","name":"networking-istio","ports":[{"containerPort":9090,"name":"metrics"}],"resources":{"limits":{"cpu":"1000m","memory":"1000Mi"},"requests":{"cpu":"100m","memory":"100Mi"}},"securityContext":{"allowPrivilegeEscalation":false},"volumeMounts":[{"mountPath":"/etc/config-logging","name":"config-logging"}]}],"serviceAccountName":"controller","volumes":[{"configMap":{"name":"config-logging"},"name":"config-logging"}]}}}}
    labels:
      networking.knative.dev/ingress-provider: istio
      serving.knative.dev/release: v0.7.0
    name: networking-istio
    namespace: knative-serving
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: networking-istio
    template:
      metadata:
        annotations:
          sidecar.istio.io/inject: "false"
        labels:
          app: networking-istio
      spec:
        containers:
        - env:
          - name: SYSTEM_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: CONFIG_LOGGING_NAME
            value: config-logging
          - name: CONFIG_OBSERVABILITY_NAME
            value: config-observability
          - name: METRICS_DOMAIN
            value: knative.dev/serving
          image: gcr.io/knative-releases/github.com/knative/serving/cmd/networking/istio@sha256:bb4407e4714511cd9429e86536c283265629a2c11c80633d91c0f798c494a16f
          name: networking-istio
          ports:
          - containerPort: 9090
            name: metrics
          resources:
            limits:
              cpu: 1000m
              memory: 1000Mi
            requests:
              cpu: 100m
              memory: 100Mi
          securityContext:
            allowPrivilegeEscalation: false
          volumeMounts:
          - mountPath: /etc/config-logging
            name: config-logging
        serviceAccountName: controller
        volumes:
        - configMap:
            name: config-logging
          name: config-logging
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"serving.knative.dev/release":"v0.7.0"},"name":"webhook","namespace":"knative-serving"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"webhook","role":"webhook"}},"template":{"metadata":{"annotations":{"cluster-autoscaler.kubernetes.io/safe-to-evict":"false","sidecar.istio.io/inject":"false"},"labels":{"app":"webhook","role":"webhook","serving.knative.dev/release":"v0.7.0"}},"spec":{"containers":[{"env":[{"name":"SYSTEM_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}},{"name":"CONFIG_LOGGING_NAME","value":"config-logging"}],"image":"gcr.io/knative-releases/github.com/knative/serving/cmd/webhook@sha256:d9918d40492e0b20b48576ff6182e2ab896e50dfd2313cb471419be98f821b9c","name":"webhook","resources":{"limits":{"cpu":"200m","memory":"200Mi"},"requests":{"cpu":"20m","memory":"20Mi"}},"securityContext":{"allowPrivilegeEscalation":false},"volumeMounts":[{"mountPath":"/etc/config-logging","name":"config-logging"}]}],"serviceAccountName":"controller","volumes":[{"configMap":{"name":"config-logging"},"name":"config-logging"}]}}}}
    labels:
      serving.knative.dev/release: v0.7.0
    name: webhook
    namespace: knative-serving
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: webhook
        role: webhook
    template:
      metadata:
        annotations:
          cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
          sidecar.istio.io/inject: "false"
        labels:
          app: webhook
          role: webhook
          serving.knative.dev/release: v0.7.0
      spec:
        containers:
        - env:
          - name: SYSTEM_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: CONFIG_LOGGING_NAME
            value: config-logging
          image: gcr.io/knative-releases/github.com/knative/serving/cmd/webhook@sha256:d9918d40492e0b20b48576ff6182e2ab896e50dfd2313cb471419be98f821b9c
          name: webhook
          resources:
            limits:
              cpu: 200m
              memory: 200Mi
            requests:
              cpu: 20m
              memory: 20Mi
          securityContext:
            allowPrivilegeEscalation: false
          volumeMounts:
          - mountPath: /etc/config-logging
            name: config-logging
        serviceAccountName: controller
        volumes:
        - configMap:
            name: config-logging
          name: config-logging
- apiVersion: v1
  kind: Namespace
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Namespace","metadata":{"annotations":{},"name":"knative-build"}}
    name: knative-build
- apiVersion: policy/v1beta1
  kind: PodSecurityPolicy
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"policy/v1beta1","kind":"PodSecurityPolicy","metadata":{"annotations":{},"name":"knative-build"},"spec":{"allowPrivilegeEscalation":false,"fsGroup":{"ranges":[{"max":65535,"min":1}],"rule":"MustRunAs"},"hostIPC":false,"hostNetwork":false,"hostPID":false,"privileged":false,"runAsUser":{"rule":"RunAsAny"},"seLinux":{"rule":"RunAsAny"},"supplementalGroups":{"ranges":[{"max":65535,"min":1}],"rule":"MustRunAs"},"volumes":["configMap","secret"]}}
    name: knative-build
  spec:
    allowPrivilegeEscalation: false
    fsGroup:
      ranges:
      - max: 65535
        min: 1
      rule: MustRunAs
    hostIPC: false
    hostNetwork: false
    hostPID: false
    privileged: false
    runAsUser:
      rule: RunAsAny
    seLinux:
      rule: RunAsAny
    supplementalGroups:
      ranges:
      - max: 65535
        min: 1
      rule: MustRunAs
    volumes:
    - configMap
    - secret
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"name":"knative-build-admin"},"rules":[{"apiGroups":[""],"resources":["pods","namespaces","secrets","events","serviceaccounts","configmaps"],"verbs":["get","list","create","update","delete","patch","watch"]},{"apiGroups":["apps"],"resources":["deployments","deployments/finalizers"],"verbs":["get","list","create","update","delete","patch","watch"]},{"apiGroups":["admissionregistration.k8s.io"],"resources":["mutatingwebhookconfigurations"],"verbs":["get","list","create","update","delete","patch","watch"]},{"apiGroups":["apiextensions.k8s.io"],"resources":["customresourcedefinitions"],"verbs":["get","list","create","update","delete","patch","watch"]},{"apiGroups":["build.knative.dev"],"resources":["builds","buildtemplates","clusterbuildtemplates"],"verbs":["get","list","create","update","delete","patch","watch"]},{"apiGroups":["build.knative.dev"],"resources":["builds/status","buildtemplates/status","clusterbuildtemplates/status"],"verbs":["get","list","create","update","delete","patch","watch"]},{"apiGroups":["caching.internal.knative.dev"],"resources":["images"],"verbs":["get","list","create","update","delete","deletecollection","patch","watch"]},{"apiGroups":["policy"],"resourceNames":["knative-build"],"resources":["podsecuritypolicies"],"verbs":["use"]}]}
    name: knative-build-admin
  rules:
  - apiGroups:
    - ""
    resources:
    - pods
    - namespaces
    - secrets
    - events
    - serviceaccounts
    - configmaps
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
  - apiGroups:
    - apps
    resources:
    - deployments
    - deployments/finalizers
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
  - apiGroups:
    - admissionregistration.k8s.io
    resources:
    - mutatingwebhookconfigurations
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
  - apiGroups:
    - apiextensions.k8s.io
    resources:
    - customresourcedefinitions
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
  - apiGroups:
    - build.knative.dev
    resources:
    - builds
    - buildtemplates
    - clusterbuildtemplates
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
  - apiGroups:
    - build.knative.dev
    resources:
    - builds/status
    - buildtemplates/status
    - clusterbuildtemplates/status
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
  - apiGroups:
    - caching.internal.knative.dev
    resources:
    - images
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - deletecollection
    - patch
    - watch
  - apiGroups:
    - policy
    resourceNames:
    - knative-build
    resources:
    - podsecuritypolicies
    verbs:
    - use
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"ServiceAccount","metadata":{"annotations":{},"name":"build-controller","namespace":"knative-build"}}
    name: build-controller
    namespace: knative-build
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"name":"build-controller-admin"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"knative-build-admin"},"subjects":[{"kind":"ServiceAccount","name":"build-controller","namespace":"knative-build"}]}
    name: build-controller-admin
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: knative-build-admin
  subjects:
  - kind: ServiceAccount
    name: build-controller
    namespace: knative-build
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"app":"build-controller"},"name":"build-controller","namespace":"knative-build"},"spec":{"ports":[{"name":"metrics","port":9090,"protocol":"TCP","targetPort":9090}],"selector":{"app":"build-controller"}}}
    labels:
      app: build-controller
    name: build-controller
    namespace: knative-build
  spec:
    ports:
    - name: metrics
      port: 9090
      protocol: TCP
      targetPort: 9090
    selector:
      app: build-controller
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"role":"build-webhook"},"name":"build-webhook","namespace":"knative-build"},"spec":{"ports":[{"port":443,"targetPort":8443}],"selector":{"role":"build-webhook"}}}
    labels:
      role: build-webhook
    name: build-webhook
    namespace: knative-build
  spec:
    ports:
    - port: 443
      targetPort: 8443
    selector:
      role: build-webhook
- apiVersion: caching.internal.knative.dev/v1alpha1
  kind: Image
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"caching.internal.knative.dev/v1alpha1","kind":"Image","metadata":{"annotations":{},"name":"creds-init","namespace":"knative-build"},"spec":{"image":"gcr.io/knative-releases/github.com/knative/build/cmd/creds-init@sha256:1a984c032a2606f8491f4a19a85209dcc1ae2cfd494c3dafe8a74269379ad2c8"}}
    name: creds-init
    namespace: knative-build
  spec:
    image: gcr.io/knative-releases/github.com/knative/build/cmd/creds-init@sha256:1a984c032a2606f8491f4a19a85209dcc1ae2cfd494c3dafe8a74269379ad2c8
- apiVersion: caching.internal.knative.dev/v1alpha1
  kind: Image
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"caching.internal.knative.dev/v1alpha1","kind":"Image","metadata":{"annotations":{},"name":"git-init","namespace":"knative-build"},"spec":{"image":"gcr.io/knative-releases/github.com/knative/build/cmd/git-init@sha256:06505d8c621e9337d0dd1bc13ed4545a33e857fbb6374740cc6337d2ba55796d"}}
    name: git-init
    namespace: knative-build
  spec:
    image: gcr.io/knative-releases/github.com/knative/build/cmd/git-init@sha256:06505d8c621e9337d0dd1bc13ed4545a33e857fbb6374740cc6337d2ba55796d
- apiVersion: caching.internal.knative.dev/v1alpha1
  kind: Image
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"caching.internal.knative.dev/v1alpha1","kind":"Image","metadata":{"annotations":{},"name":"gcs-fetcher","namespace":"knative-build"},"spec":{"image":"gcr.io/cloud-builders/gcs-fetcher"}}
    name: gcs-fetcher
    namespace: knative-build
  spec:
    image: gcr.io/cloud-builders/gcs-fetcher
- apiVersion: caching.internal.knative.dev/v1alpha1
  kind: Image
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"caching.internal.knative.dev/v1alpha1","kind":"Image","metadata":{"annotations":{},"name":"nop","namespace":"knative-build"},"spec":{"image":"gcr.io/knative-releases/github.com/knative/build/cmd/nop@sha256:8aca9c97ede9a550ac3536d00c5d7acaae5e3a4fe514f4329ec261d935eddabb"}}
    name: nop
    namespace: knative-build
  spec:
    image: gcr.io/knative-releases/github.com/knative/build/cmd/nop@sha256:8aca9c97ede9a550ac3536d00c5d7acaae5e3a4fe514f4329ec261d935eddabb
- apiVersion: v1
  data:
    loglevel.controller: info
    loglevel.creds-init: info
    loglevel.git-init: info
    loglevel.webhook: info
    zap-logger-config: |
      {
        "level": "info",
        "development": false,
        "sampling": {
          "initial": 100,
          "thereafter": 100
        },
        "outputPaths": ["stdout"],
        "errorOutputPaths": ["stderr"],
        "encoding": "json",
        "encoderConfig": {
          "timeKey": "",
          "levelKey": "level",
          "nameKey": "logger",
          "callerKey": "caller",
          "messageKey": "msg",
          "stacktraceKey": "stacktrace",
          "lineEnding": "",
          "levelEncoder": "",
          "timeEncoder": "",
          "durationEncoder": "",
          "callerEncoder": ""
        }
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"loglevel.controller":"info","loglevel.creds-init":"info","loglevel.git-init":"info","loglevel.webhook":"info","zap-logger-config":"{\n  \"level\": \"info\",\n  \"development\": false,\n  \"sampling\": {\n    \"initial\": 100,\n    \"thereafter\": 100\n  },\n  \"outputPaths\": [\"stdout\"],\n  \"errorOutputPaths\": [\"stderr\"],\n  \"encoding\": \"json\",\n  \"encoderConfig\": {\n    \"timeKey\": \"\",\n    \"levelKey\": \"level\",\n    \"nameKey\": \"logger\",\n    \"callerKey\": \"caller\",\n    \"messageKey\": \"msg\",\n    \"stacktraceKey\": \"stacktrace\",\n    \"lineEnding\": \"\",\n    \"levelEncoder\": \"\",\n    \"timeEncoder\": \"\",\n    \"durationEncoder\": \"\",\n    \"callerEncoder\": \"\"\n  }\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"config-logging","namespace":"knative-build"}}
    name: config-logging
    namespace: knative-build
- apiVersion: v1
  data:
    _example: |
      ################################
      #                              #
      #    EXAMPLE CONFIGURATION     #
      #                              #
      ################################

      # This block is not actually functional configuration,
      # but serves to illustrate the available configuration
      # options and document them in a way that is accessible
      # to users that `kubectl edit` this config map.
      #
      # These sample configuration options may be copied out of
      # this example block and unindented to be in the data block
      # to actually change the configuration.

      # metrics.backend-destination field specifies the system metrics destination.
      # It supports either prometheus (the default) or stackdriver.
      # Note: Using stackdriver will incur additional charges
      metrics.backend-destination: prometheus

      # metrics.stackdriver-project-id field specifies the stackdriver project ID. This
      # field is optional. When running on GCE, application default credentials will be
      # used if this field is not provided.
      metrics.stackdriver-project-id: "<your stackdriver project id>"

      # metrics.allow-stackdriver-custom-metrics indicates whether it is allowed to send metrics to
      # Stackdriver using "global" resource type and custom metric type if the
      # metrics are not supported by "knative_revision" resource type. Setting this
      # flag to "true" could cause extra Stackdriver charge.
      # If metrics.backend-destination is not Stackdriver, this is ignored.
      metrics.allow-stackdriver-custom-metrics: "false"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"_example":"################################\n#                              #\n#    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\n# This block is not actually functional configuration,\n# but serves to illustrate the available configuration\n# options and document them in a way that is accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample configuration options may be copied out of\n# this example block and unindented to be in the data block\n# to actually change the configuration.\n\n# metrics.backend-destination field specifies the system metrics destination.\n# It supports either prometheus (the default) or stackdriver.\n# Note: Using stackdriver will incur additional charges\nmetrics.backend-destination: prometheus\n\n# metrics.stackdriver-project-id field specifies the stackdriver project ID. This\n# field is optional. When running on GCE, application default credentials will be\n# used if this field is not provided.\nmetrics.stackdriver-project-id: \"\u003cyour stackdriver project id\u003e\"\n\n# metrics.allow-stackdriver-custom-metrics indicates whether it is allowed to send metrics to\n# Stackdriver using \"global\" resource type and custom metric type if the\n# metrics are not supported by \"knative_revision\" resource type. Setting this\n# flag to \"true\" could cause extra Stackdriver charge.\n# If metrics.backend-destination is not Stackdriver, this is ignored.\nmetrics.allow-stackdriver-custom-metrics: \"false\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"config-observability","namespace":"knative-build"}}
    name: config-observability
    namespace: knative-build
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"name":"build-controller","namespace":"knative-build"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"build-controller"}},"template":{"metadata":{"labels":{"app":"build-controller"}},"spec":{"containers":[{"args":["-logtostderr","-stderrthreshold","INFO","-creds-image","gcr.io/knative-releases/github.com/knative/build/cmd/creds-init@sha256:1a984c032a2606f8491f4a19a85209dcc1ae2cfd494c3dafe8a74269379ad2c8","-git-image","gcr.io/knative-releases/github.com/knative/build/cmd/git-init@sha256:06505d8c621e9337d0dd1bc13ed4545a33e857fbb6374740cc6337d2ba55796d","-nop-image","gcr.io/knative-releases/github.com/knative/build/cmd/nop@sha256:8aca9c97ede9a550ac3536d00c5d7acaae5e3a4fe514f4329ec261d935eddabb"],"env":[{"name":"SYSTEM_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}},{"name":"CONFIG_LOGGING_NAME","value":"config-logging"},{"name":"CONFIG_OBSERVABILITY_NAME","value":"config-observability"},{"name":"METRICS_DOMAIN","value":"knative.dev/build"}],"image":"gcr.io/knative-releases/github.com/knative/build/cmd/controller@sha256:5adb5ba0647a7b1af1d90848bf72a75fa84efeb89e1d688465a2105c1cce1dc2","name":"build-controller","ports":[{"containerPort":9090,"name":"metrics"}],"resources":{"limits":{"cpu":"1000m","memory":"1000Mi"},"requests":{"cpu":"100m","memory":"100Mi"}},"volumeMounts":[{"mountPath":"/etc/config-logging","name":"config-logging"}]}],"serviceAccountName":"build-controller","volumes":[{"configMap":{"name":"config-logging"},"name":"config-logging"}]}}}}
    name: build-controller
    namespace: knative-build
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: build-controller
    template:
      metadata:
        labels:
          app: build-controller
      spec:
        containers:
        - args:
          - -logtostderr
          - -stderrthreshold
          - INFO
          - -creds-image
          - gcr.io/knative-releases/github.com/knative/build/cmd/creds-init@sha256:1a984c032a2606f8491f4a19a85209dcc1ae2cfd494c3dafe8a74269379ad2c8
          - -git-image
          - gcr.io/knative-releases/github.com/knative/build/cmd/git-init@sha256:06505d8c621e9337d0dd1bc13ed4545a33e857fbb6374740cc6337d2ba55796d
          - -nop-image
          - gcr.io/knative-releases/github.com/knative/build/cmd/nop@sha256:8aca9c97ede9a550ac3536d00c5d7acaae5e3a4fe514f4329ec261d935eddabb
          env:
          - name: SYSTEM_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: CONFIG_LOGGING_NAME
            value: config-logging
          - name: CONFIG_OBSERVABILITY_NAME
            value: config-observability
          - name: METRICS_DOMAIN
            value: knative.dev/build
          image: gcr.io/knative-releases/github.com/knative/build/cmd/controller@sha256:5adb5ba0647a7b1af1d90848bf72a75fa84efeb89e1d688465a2105c1cce1dc2
          name: build-controller
          ports:
          - containerPort: 9090
            name: metrics
          resources:
            limits:
              cpu: 1000m
              memory: 1000Mi
            requests:
              cpu: 100m
              memory: 100Mi
          volumeMounts:
          - mountPath: /etc/config-logging
            name: config-logging
        serviceAccountName: build-controller
        volumes:
        - configMap:
            name: config-logging
          name: config-logging
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"name":"build-webhook","namespace":"knative-build"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"build-webhook"}},"template":{"metadata":{"labels":{"app":"build-webhook","role":"build-webhook"}},"spec":{"containers":[{"args":["-logtostderr","-stderrthreshold","INFO"],"env":[{"name":"SYSTEM_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"gcr.io/knative-releases/github.com/knative/build/cmd/webhook@sha256:35b1b5f72642e9c1ee71809fec309a019111beebf805f9ddddf154a97ad23975","name":"build-webhook","resources":{"limits":{"memory":"1000Mi"}},"volumeMounts":[{"mountPath":"/etc/config-logging","name":"config-logging"}]}],"serviceAccountName":"build-controller","volumes":[{"configMap":{"name":"config-logging"},"name":"config-logging"}]}}}}
    name: build-webhook
    namespace: knative-build
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: build-webhook
    template:
      metadata:
        labels:
          app: build-webhook
          role: build-webhook
      spec:
        containers:
        - args:
          - -logtostderr
          - -stderrthreshold
          - INFO
          env:
          - name: SYSTEM_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          image: gcr.io/knative-releases/github.com/knative/build/cmd/webhook@sha256:35b1b5f72642e9c1ee71809fec309a019111beebf805f9ddddf154a97ad23975
          name: build-webhook
          resources:
            limits:
              memory: 1000Mi
          volumeMounts:
          - mountPath: /etc/config-logging
            name: config-logging
        serviceAccountName: build-controller
        volumes:
        - configMap:
            name: config-logging
          name: config-logging
- apiVersion: v1
  kind: Namespace
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Namespace","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"knative-eventing"}}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: knative-eventing
- aggregationRule:
    clusterRoleSelectors:
    - matchLabels:
        duck.knative.dev/addressable: "true"
  apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"aggregationRule":{"clusterRoleSelectors":[{"matchLabels":{"duck.knative.dev/addressable":"true"}}]},"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"addressable-resolver"},"rules":[]}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: addressable-resolver
  rules: []
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"duck.knative.dev/addressable":"true","eventing.knative.dev/release":"v0.7.0"},"name":"service-addressable-resolver"},"rules":[{"apiGroups":[""],"resources":["services"],"verbs":["get","list","watch"]}]}
    labels:
      duck.knative.dev/addressable: "true"
      eventing.knative.dev/release: v0.7.0
    name: service-addressable-resolver
  rules:
  - apiGroups:
    - ""
    resources:
    - services
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"duck.knative.dev/addressable":"true","eventing.knative.dev/release":"v0.7.0"},"name":"serving-addressable-resolver"},"rules":[{"apiGroups":["serving.knative.dev"],"resources":["routes","routes/status","services","services/status"],"verbs":["get","list","watch"]}]}
    labels:
      duck.knative.dev/addressable: "true"
      eventing.knative.dev/release: v0.7.0
    name: serving-addressable-resolver
  rules:
  - apiGroups:
    - serving.knative.dev
    resources:
    - routes
    - routes/status
    - services
    - services/status
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"duck.knative.dev/addressable":"true","eventing.knative.dev/release":"v0.7.0"},"name":"channel-addressable-resolver"},"rules":[{"apiGroups":["eventing.knative.dev"],"resources":["channels","channels/status"],"verbs":["get","list","watch"]}]}
    labels:
      duck.knative.dev/addressable: "true"
      eventing.knative.dev/release: v0.7.0
    name: channel-addressable-resolver
  rules:
  - apiGroups:
    - eventing.knative.dev
    resources:
    - channels
    - channels/status
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"duck.knative.dev/addressable":"true","eventing.knative.dev/release":"v0.7.0"},"name":"broker-addressable-resolver"},"rules":[{"apiGroups":["eventing.knative.dev"],"resources":["brokers","brokers/status"],"verbs":["get","list","watch"]}]}
    labels:
      duck.knative.dev/addressable: "true"
      eventing.knative.dev/release: v0.7.0
    name: broker-addressable-resolver
  rules:
  - apiGroups:
    - eventing.knative.dev
    resources:
    - brokers
    - brokers/status
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"eventing-broker-filter"},"rules":[{"apiGroups":[""],"resources":["configmaps"],"verbs":["get","list","watch"]},{"apiGroups":["eventing.knative.dev"],"resources":["triggers","triggers/status"],"verbs":["get","list","watch"]}]}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: eventing-broker-filter
  rules:
  - apiGroups:
    - ""
    resources:
    - configmaps
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - eventing.knative.dev
    resources:
    - triggers
    - triggers/status
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"eventing-broker-ingress"},"rules":[{"apiGroups":[""],"resources":["configmaps"],"verbs":["get","list","watch"]}]}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: eventing-broker-ingress
  rules:
  - apiGroups:
    - ""
    resources:
    - configmaps
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"eventing-config-reader"},"rules":[{"apiGroups":[""],"resources":["configmaps"],"verbs":["get","list","watch"]}]}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: eventing-config-reader
  rules:
  - apiGroups:
    - ""
    resources:
    - configmaps
    verbs:
    - get
    - list
    - watch
- aggregationRule:
    clusterRoleSelectors:
    - matchLabels:
        duck.knative.dev/channelable: "true"
  apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"aggregationRule":{"clusterRoleSelectors":[{"matchLabels":{"duck.knative.dev/channelable":"true"}}]},"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"channelable-manipulator"},"rules":[]}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: channelable-manipulator
  rules: []
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"knative-eventing-controller"},"rules":[{"apiGroups":[""],"resources":["namespaces","secrets","configmaps","services","events","serviceaccounts"],"verbs":["get","list","create","update","delete","patch","watch"]},{"apiGroups":["apps"],"resources":["deployments"],"verbs":["get","list","create","update","delete","patch","watch"]},{"apiGroups":["rbac.authorization.k8s.io"],"resources":["rolebindings"],"verbs":["get","list","create","update","delete","patch","watch"]},{"apiGroups":["eventing.knative.dev"],"resources":["brokers","brokers/status","channels","channels/status","clusterchannelprovisioners","clusterchannelprovisioners/status","subscriptions","subscriptions/status","triggers","triggers/status","eventtypes","eventtypes/status"],"verbs":["get","list","create","update","delete","patch","watch"]},{"apiGroups":["eventing.knative.dev"],"resources":["brokers/finalizers","triggers/finalizers"],"verbs":["update"]},{"apiGroups":["messaging.knative.dev"],"resources":["sequences","sequences/status"],"verbs":["get","list","create","update","delete","patch","watch"]},{"apiGroups":["sources.eventing.knative.dev"],"resources":["cronjobsources","cronjobsources/status","cronjobsources/finalizers","containersources","containersources/status","containersources/finalizers","apiserversources","apiserversources/status","apiserversources/finalizers"],"verbs":["get","list","create","update","delete","patch","watch"]},{"apiGroups":["apiextensions.k8s.io"],"resources":["customresourcedefinitions"],"verbs":["get","list","watch"]}]}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: knative-eventing-controller
  rules:
  - apiGroups:
    - ""
    resources:
    - namespaces
    - secrets
    - configmaps
    - services
    - events
    - serviceaccounts
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
  - apiGroups:
    - apps
    resources:
    - deployments
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
  - apiGroups:
    - rbac.authorization.k8s.io
    resources:
    - rolebindings
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
  - apiGroups:
    - eventing.knative.dev
    resources:
    - brokers
    - brokers/status
    - channels
    - channels/status
    - clusterchannelprovisioners
    - clusterchannelprovisioners/status
    - subscriptions
    - subscriptions/status
    - triggers
    - triggers/status
    - eventtypes
    - eventtypes/status
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
  - apiGroups:
    - eventing.knative.dev
    resources:
    - brokers/finalizers
    - triggers/finalizers
    verbs:
    - update
  - apiGroups:
    - messaging.knative.dev
    resources:
    - sequences
    - sequences/status
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
  - apiGroups:
    - sources.eventing.knative.dev
    resources:
    - cronjobsources
    - cronjobsources/status
    - cronjobsources/finalizers
    - containersources
    - containersources/status
    - containersources/finalizers
    - apiserversources
    - apiserversources/status
    - apiserversources/finalizers
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
  - apiGroups:
    - apiextensions.k8s.io
    resources:
    - customresourcedefinitions
    verbs:
    - get
    - list
    - watch
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"ServiceAccount","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"eventing-controller","namespace":"knative-eventing"}}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: eventing-controller
    namespace: knative-eventing
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"ServiceAccount","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"eventing-webhook","namespace":"knative-eventing"}}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: eventing-webhook
    namespace: knative-eventing
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"knative-eventing-webhook"},"rules":[{"apiGroups":[""],"resources":["configmaps"],"verbs":["get","list","watch"]},{"apiGroups":[""],"resources":["secrets"],"verbs":["get","create"]},{"apiGroups":["apps"],"resources":["deployments"],"verbs":["get"]},{"apiGroups":["apps"],"resources":["deployments/finalizers"],"verbs":["update"]},{"apiGroups":["admissionregistration.k8s.io"],"resources":["mutatingwebhookconfigurations"],"verbs":["get","list","create","update","delete","patch","watch"]},{"apiGroups":["eventing.knative.dev"],"resources":["brokers","brokers/status","channels","channels/status","clusterchannelprovisioners","clusterchannelprovisioners/status","subscriptions","subscriptions/status","triggers","triggers/status","eventtypes","eventtypes/status"],"verbs":["get","list","watch"]}]}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: knative-eventing-webhook
  rules:
  - apiGroups:
    - ""
    resources:
    - configmaps
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - secrets
    verbs:
    - get
    - create
  - apiGroups:
    - apps
    resources:
    - deployments
    verbs:
    - get
  - apiGroups:
    - apps
    resources:
    - deployments/finalizers
    verbs:
    - update
  - apiGroups:
    - admissionregistration.k8s.io
    resources:
    - mutatingwebhookconfigurations
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
  - apiGroups:
    - eventing.knative.dev
    resources:
    - brokers
    - brokers/status
    - channels
    - channels/status
    - clusterchannelprovisioners
    - clusterchannelprovisioners/status
    - subscriptions
    - subscriptions/status
    - triggers
    - triggers/status
    - eventtypes
    - eventtypes/status
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"eventing-controller"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"knative-eventing-controller"},"subjects":[{"kind":"ServiceAccount","name":"eventing-controller","namespace":"knative-eventing"}]}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: eventing-controller
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: knative-eventing-controller
  subjects:
  - kind: ServiceAccount
    name: eventing-controller
    namespace: knative-eventing
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"eventing-controller-resolver"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"addressable-resolver"},"subjects":[{"kind":"ServiceAccount","name":"eventing-controller","namespace":"knative-eventing"}]}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: eventing-controller-resolver
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: addressable-resolver
  subjects:
  - kind: ServiceAccount
    name: eventing-controller
    namespace: knative-eventing
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"eventing-controller-manipulator"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"channelable-manipulator"},"subjects":[{"kind":"ServiceAccount","name":"eventing-controller","namespace":"knative-eventing"}]}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: eventing-controller-manipulator
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: channelable-manipulator
  subjects:
  - kind: ServiceAccount
    name: eventing-controller
    namespace: knative-eventing
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"eventing-webhook"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"knative-eventing-webhook"},"subjects":[{"kind":"ServiceAccount","name":"eventing-webhook","namespace":"knative-eventing"}]}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: eventing-webhook
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: knative-eventing-webhook
  subjects:
  - kind: ServiceAccount
    name: eventing-webhook
    namespace: knative-eventing
- apiVersion: v1
  data:
    default-channel-config: |
      clusterdefault:
        apiversion: eventing.knative.dev/v1alpha1
        kind: ClusterChannelProvisioner
        name: in-memory
      namespacedefaults:
        some-namespace:
          apiversion: eventing.knative.dev/v1alpha1
          kind: ClusterChannelProvisioner
          name: some-other-provisioner
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"default-channel-config":"clusterdefault:\n  apiversion: eventing.knative.dev/v1alpha1\n  kind: ClusterChannelProvisioner\n  name: in-memory\nnamespacedefaults:\n  some-namespace:\n    apiversion: eventing.knative.dev/v1alpha1\n    kind: ClusterChannelProvisioner\n    name: some-other-provisioner\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"default-channel-webhook","namespace":"knative-eventing"}}
    name: default-channel-webhook
    namespace: knative-eventing
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"app":"sources-controller","eventing.knative.dev/release":"v0.7.0"},"name":"sources-controller","namespace":"knative-eventing"},"spec":{"ports":[{"name":"metrics","port":9090,"protocol":"TCP","targetPort":9090}],"selector":{"app":"sources-controller"}}}
    labels:
      app: sources-controller
      eventing.knative.dev/release: v0.7.0
    name: sources-controller
    namespace: knative-eventing
  spec:
    ports:
    - name: metrics
      port: 9090
      protocol: TCP
      targetPort: 9090
    selector:
      app: sources-controller
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0","role":"eventing-webhook"},"name":"eventing-webhook","namespace":"knative-eventing"},"spec":{"ports":[{"port":443,"targetPort":8443}],"selector":{"role":"eventing-webhook"}}}
    labels:
      eventing.knative.dev/release: v0.7.0
      role: eventing-webhook
    name: eventing-webhook
    namespace: knative-eventing
  spec:
    ports:
    - port: 443
      targetPort: 8443
    selector:
      role: eventing-webhook
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"eventing-controller","namespace":"knative-eventing"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"eventing-controller"}},"template":{"metadata":{"annotations":{"sidecar.istio.io/inject":"false"},"labels":{"app":"eventing-controller","eventing.knative.dev/release":"v0.7.0"}},"spec":{"containers":[{"env":[{"name":"SYSTEM_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}},{"name":"CONFIG_LOGGING_NAME","value":"config-logging"},{"name":"CONFIG_OBSERVABILITY_NAME","value":"config-observability"},{"name":"METRICS_DOMAIN","value":"knative.dev/eventing"},{"name":"BROKER_INGRESS_IMAGE","value":"gcr.io/knative-releases/github.com/knative/eventing/cmd/broker/ingress@sha256:33d41dc38208bf9752b38e5c90149da4d5af74a67f317b7da8cb3c458fbd0fff"},{"name":"BROKER_INGRESS_SERVICE_ACCOUNT","value":"eventing-broker-ingress"},{"name":"BROKER_FILTER_IMAGE","value":"gcr.io/knative-releases/github.com/knative/eventing/cmd/broker/filter@sha256:5a4eb60a605e189516a36a01c7fd39001d5766b2e6bb80c69744e15515282360"},{"name":"BROKER_FILTER_SERVICE_ACCOUNT","value":"eventing-broker-filter"}],"image":"gcr.io/knative-releases/github.com/knative/eventing/cmd/controller@sha256:57f273774efb017bbf06729af802514db2f3ab070b51730dba9330903aa34163","name":"eventing-controller","ports":[{"containerPort":9090,"name":"metrics"}],"terminationMessagePolicy":"FallbackToLogsOnError","volumeMounts":[{"mountPath":"/etc/config-logging","name":"config-logging"}]}],"serviceAccountName":"eventing-controller","volumes":[{"configMap":{"name":"config-logging"},"name":"config-logging"}]}}}}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: eventing-controller
    namespace: knative-eventing
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: eventing-controller
    template:
      metadata:
        annotations:
          sidecar.istio.io/inject: "false"
        labels:
          app: eventing-controller
          eventing.knative.dev/release: v0.7.0
      spec:
        containers:
        - env:
          - name: SYSTEM_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: CONFIG_LOGGING_NAME
            value: config-logging
          - name: CONFIG_OBSERVABILITY_NAME
            value: config-observability
          - name: METRICS_DOMAIN
            value: knative.dev/eventing
          - name: BROKER_INGRESS_IMAGE
            value: gcr.io/knative-releases/github.com/knative/eventing/cmd/broker/ingress@sha256:33d41dc38208bf9752b38e5c90149da4d5af74a67f317b7da8cb3c458fbd0fff
          - name: BROKER_INGRESS_SERVICE_ACCOUNT
            value: eventing-broker-ingress
          - name: BROKER_FILTER_IMAGE
            value: gcr.io/knative-releases/github.com/knative/eventing/cmd/broker/filter@sha256:5a4eb60a605e189516a36a01c7fd39001d5766b2e6bb80c69744e15515282360
          - name: BROKER_FILTER_SERVICE_ACCOUNT
            value: eventing-broker-filter
          image: gcr.io/knative-releases/github.com/knative/eventing/cmd/controller@sha256:57f273774efb017bbf06729af802514db2f3ab070b51730dba9330903aa34163
          name: eventing-controller
          ports:
          - containerPort: 9090
            name: metrics
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
          - mountPath: /etc/config-logging
            name: config-logging
        serviceAccountName: eventing-controller
        volumes:
        - configMap:
            name: config-logging
          name: config-logging
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"sources-controller","namespace":"knative-eventing"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"sources-controller"}},"template":{"metadata":{"annotations":{"sidecar.istio.io/inject":"false"},"labels":{"app":"sources-controller","eventing.knative.dev/release":"v0.7.0"}},"spec":{"containers":[{"env":[{"name":"SYSTEM_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}},{"name":"CONFIG_LOGGING_NAME","value":"config-logging"},{"name":"CONFIG_OBSERVABILITY_NAME","value":"config-observability"},{"name":"METRICS_DOMAIN","value":"knative.dev/sources"},{"name":"CRONJOB_RA_IMAGE","value":"gcr.io/knative-releases/github.com/knative/eventing/cmd/cronjob_receive_adapter@sha256:634fbf0348f9f10d09c8110c505173aed91ce747bb2b87605e6e1bb10dce270b"},{"name":"APISERVER_RA_IMAGE","value":"gcr.io/knative-releases/github.com/knative/eventing/cmd/apiserver_receive_adapter@sha256:f18cdbc3c3077ece8505a4f4c49055e6c1c577e9fa42446f0f81193e48aa1d60"}],"image":"gcr.io/knative-releases/github.com/knative/eventing/cmd/sources_controller@sha256:31ec2b4a1d1d9b81cd1eed6632b8a1c540b510b584e58c14ebc1c000330fe32c","name":"controller","ports":[{"containerPort":9090,"name":"metrics"}],"resources":{"requests":{"cpu":"100m","memory":"100Mi"}},"volumeMounts":[{"mountPath":"/etc/config-logging","name":"config-logging"}]}],"serviceAccountName":"eventing-controller","volumes":[{"configMap":{"name":"config-logging"},"name":"config-logging"}]}}}}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: sources-controller
    namespace: knative-eventing
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: sources-controller
    template:
      metadata:
        annotations:
          sidecar.istio.io/inject: "false"
        labels:
          app: sources-controller
          eventing.knative.dev/release: v0.7.0
      spec:
        containers:
        - env:
          - name: SYSTEM_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: CONFIG_LOGGING_NAME
            value: config-logging
          - name: CONFIG_OBSERVABILITY_NAME
            value: config-observability
          - name: METRICS_DOMAIN
            value: knative.dev/sources
          - name: CRONJOB_RA_IMAGE
            value: gcr.io/knative-releases/github.com/knative/eventing/cmd/cronjob_receive_adapter@sha256:634fbf0348f9f10d09c8110c505173aed91ce747bb2b87605e6e1bb10dce270b
          - name: APISERVER_RA_IMAGE
            value: gcr.io/knative-releases/github.com/knative/eventing/cmd/apiserver_receive_adapter@sha256:f18cdbc3c3077ece8505a4f4c49055e6c1c577e9fa42446f0f81193e48aa1d60
          image: gcr.io/knative-releases/github.com/knative/eventing/cmd/sources_controller@sha256:31ec2b4a1d1d9b81cd1eed6632b8a1c540b510b584e58c14ebc1c000330fe32c
          name: controller
          ports:
          - containerPort: 9090
            name: metrics
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          volumeMounts:
          - mountPath: /etc/config-logging
            name: config-logging
        serviceAccountName: eventing-controller
        volumes:
        - configMap:
            name: config-logging
          name: config-logging
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"eventing-webhook","namespace":"knative-eventing"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"eventing-webhook","role":"eventing-webhook"}},"template":{"metadata":{"annotations":{"sidecar.istio.io/inject":"false"},"labels":{"app":"eventing-webhook","role":"eventing-webhook"}},"spec":{"containers":[{"env":[{"name":"SYSTEM_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}},{"name":"CONFIG_LOGGING_NAME","value":"config-logging"},{"name":"WEBHOOK_NAME","value":"eventing-webhook"}],"image":"gcr.io/knative-releases/github.com/knative/eventing/cmd/webhook@sha256:3b5de8074f00469c393910fd0fbac70cec10838a858c94ad755af1b6bd6712fd","name":"eventing-webhook","terminationMessagePolicy":"FallbackToLogsOnError","volumeMounts":[{"mountPath":"/etc/config-logging","name":"config-logging"}]}],"serviceAccountName":"eventing-webhook","volumes":[{"configMap":{"name":"config-logging"},"name":"config-logging"}]}}}}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: eventing-webhook
    namespace: knative-eventing
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: eventing-webhook
        role: eventing-webhook
    template:
      metadata:
        annotations:
          sidecar.istio.io/inject: "false"
        labels:
          app: eventing-webhook
          role: eventing-webhook
      spec:
        containers:
        - env:
          - name: SYSTEM_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: CONFIG_LOGGING_NAME
            value: config-logging
          - name: WEBHOOK_NAME
            value: eventing-webhook
          image: gcr.io/knative-releases/github.com/knative/eventing/cmd/webhook@sha256:3b5de8074f00469c393910fd0fbac70cec10838a858c94ad755af1b6bd6712fd
          name: eventing-webhook
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
          - mountPath: /etc/config-logging
            name: config-logging
        serviceAccountName: eventing-webhook
        volumes:
        - configMap:
            name: config-logging
          name: config-logging
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"name":"webhook","namespace":"knative-eventing"},"spec":{"replicas":0,"selector":{"matchLabels":{"app":"webhook","role":"webhook"}},"template":{"metadata":{"annotations":{"sidecar.istio.io/inject":"false"},"labels":{"app":"webhook","role":"webhook"}},"spec":{"containers":[{"env":[{"name":"SYSTEM_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}},{"name":"CONFIG_LOGGING_NAME","value":"config-logging"},{"name":"WEBHOOK_NAME","value":"webhook"}],"image":"gcr.io/knative-releases/github.com/knative/eventing/cmd/webhook@sha256:3b5de8074f00469c393910fd0fbac70cec10838a858c94ad755af1b6bd6712fd","name":"webhook","resources":{"limits":{"memory":"1000Mi"}},"terminationMessagePolicy":"FallbackToLogsOnError","volumeMounts":[{"mountPath":"/etc/config-logging","name":"config-logging"}]}],"serviceAccountName":"eventing-webhook","volumes":[{"configMap":{"name":"config-logging"},"name":"config-logging"}]}}}}
    name: webhook
    namespace: knative-eventing
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: webhook
        role: webhook
    template:
      metadata:
        annotations:
          sidecar.istio.io/inject: "false"
        labels:
          app: webhook
          role: webhook
      spec:
        containers:
        - env:
          - name: SYSTEM_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: CONFIG_LOGGING_NAME
            value: config-logging
          - name: WEBHOOK_NAME
            value: webhook
          image: gcr.io/knative-releases/github.com/knative/eventing/cmd/webhook@sha256:3b5de8074f00469c393910fd0fbac70cec10838a858c94ad755af1b6bd6712fd
          name: webhook
          resources:
            limits:
              memory: 1000Mi
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
          - mountPath: /etc/config-logging
            name: config-logging
        serviceAccountName: eventing-webhook
        volumes:
        - configMap:
            name: config-logging
          name: config-logging
- apiVersion: v1
  data:
    loglevel.controller: info
    loglevel.webhook: info
    zap-logger-config: |
      {
        "level": "info",
        "development": false,
        "outputPaths": ["stdout"],
        "errorOutputPaths": ["stderr"],
        "encoding": "json",
        "encoderConfig": {
          "timeKey": "ts",
          "levelKey": "level",
          "nameKey": "logger",
          "callerKey": "caller",
          "messageKey": "msg",
          "stacktraceKey": "stacktrace",
          "lineEnding": "",
          "levelEncoder": "",
          "timeEncoder": "iso8601",
          "durationEncoder": "",
          "callerEncoder": ""
        }
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"loglevel.controller":"info","loglevel.webhook":"info","zap-logger-config":"{\n  \"level\": \"info\",\n  \"development\": false,\n  \"outputPaths\": [\"stdout\"],\n  \"errorOutputPaths\": [\"stderr\"],\n  \"encoding\": \"json\",\n  \"encoderConfig\": {\n    \"timeKey\": \"ts\",\n    \"levelKey\": \"level\",\n    \"nameKey\": \"logger\",\n    \"callerKey\": \"caller\",\n    \"messageKey\": \"msg\",\n    \"stacktraceKey\": \"stacktrace\",\n    \"lineEnding\": \"\",\n    \"levelEncoder\": \"\",\n    \"timeEncoder\": \"iso8601\",\n    \"durationEncoder\": \"\",\n    \"callerEncoder\": \"\"\n  }\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"config-logging","namespace":"knative-eventing"}}
    name: config-logging
    namespace: knative-eventing
- apiVersion: v1
  data:
    _example: |
      ################################
      #                              #
      #    EXAMPLE CONFIGURATION     #
      #                              #
      ################################

      # This block is not actually functional configuration,
      # but serves to illustrate the available configuration
      # options and document them in a way that is accessible
      # to users that `kubectl edit` this config map.
      #
      # These sample configuration options may be copied out of
      # this example block and unindented to be in the data block
      # to actually change the configuration.

      # logging.enable-var-log-collection defaults to false.
      # A fluentd sidecar will be set up to collect var log if
      # this flag is true.
      logging.enable-var-log-collection: false

      # logging.fluentd-sidecar-image provides the fluentd sidecar image
      # to inject as a sidecar to collect logs from /var/log.
      # Must be presented if logging.enable-var-log-collection is true.
      logging.fluentd-sidecar-image: k8s.gcr.io/fluentd-elasticsearch:v2.0.4

      # logging.fluentd-sidecar-output-config provides the configuration
      # for the fluentd sidecar, which will be placed into a configmap and
      # mounted into the fluentd sidecar image.
      logging.fluentd-sidecar-output-config: |
        # Parse json log before sending to Elastic Search
        <filter **>
          @type parser
          key_name log
          <parse>
            @type multi_format
            <pattern>
              format json
              time_key fluentd-time # fluentd-time is reserved for structured logs
              time_format %Y-%m-%dT%H:%M:%S.%NZ
            </pattern>
            <pattern>
              format none
              message_key log
            </pattern>
          </parse>
        </filter>
        # Send to Elastic Search
        <match **>
          @id elasticsearch
          @type elasticsearch
          @log_level info
          include_tag_key true
          # Elasticsearch service is in monitoring namespace.
          host elasticsearch-logging.knative-monitoring
          port 9200
          logstash_format true
          <buffer>
            @type file
            path /var/log/fluentd-buffers/kubernetes.system.buffer
            flush_mode interval
            retry_type exponential_backoff
            flush_thread_count 2
            flush_interval 5s
            retry_forever
            retry_max_interval 30
            chunk_limit_size 2M
            queue_limit_length 8
            overflow_action block
          </buffer>
        </match>

      # logging.revision-url-template provides a template to use for producing the
      # logging URL that is injected into the status of each Revision.
      # This value is what you might use the the Knative monitoring bundle, and provides
      # access to Kibana after setting up kubectl proxy.
      logging.revision-url-template: |
        http://localhost:8001/api/v1/namespaces/knative-monitoring/services/kibana-logging/proxy/app/kibana#/discover?_a=(query:(match:(kubernetes.labels.knative-dev%2FrevisionUID:(query:'${REVISION_UID}',type:phrase))))

      # If non-empty, this enables queue proxy writing request logs to stdout.
      # The value determines the shape of the request logs and it must be a valid go text/template.
      # It is important to keep this as a single line. Multiple lines are parsed as separate entities
      # by most collection agents and will split the request logs into multiple records.
      #
      # The following fields and functions are available to the template:
      #
      # Request: An http.Request (see https://golang.org/pkg/net/http/#Request)
      # representing an HTTP request received by the server.
      #
      # Response:
      # struct {
      #   Code    int       // HTTP status code (see https://www.iana.org/assignments/http-status-codes/http-status-codes.xhtml)
      #   Size    int       // An int representing the size of the response.
      #   Latency float64   // A float64 representing the latency of the response in seconds.
      # }
      #
      # Revision:
      # struct {
      #   Name          string  // Knative revision name
      #   Namespace     string  // Knative revision namespace
      #   Service       string  // Knative service name
      #   Configuration string  // Knative configuration name
      #   PodName       string  // Name of the pod hosting the revision
      #   PodIP         string  // IP of the pod hosting the revision
      # }
      #
      logging.request-log-template: '{"httpRequest": {"requestMethod": "{{.Request.Method}}", "requestUrl": "{{js .Request.RequestURI}}", "requestSize": "{{.Request.ContentLength}}", "status": {{.Response.Code}}, "responseSize": "{{.Response.Size}}", "userAgent": "{{js .Request.UserAgent}}", "remoteIp": "{{js .Request.RemoteAddr}}", "serverIp": "{{.Revision.PodIP}}", "referer": "{{js .Request.Referer}}", "latency": "{{.Response.Latency}}s", "protocol": "{{.Request.Proto}}"}, "traceId": "{{index .Request.Header "X-B3-Traceid"}}"}'

      # metrics.backend-destination field specifies the system metrics destination.
      # It supports either prometheus (the default) or stackdriver.
      # Note: Using stackdriver will incur additional charges
      metrics.backend-destination: prometheus

      # metrics.request-metrics-backend-destination specifies the request metrics
      # destination. If non-empty, it enables queue proxy to send request metrics.
      # Currently supported values: prometheus, stackdriver.
      metrics.request-metrics-backend-destination: prometheus

      # metrics.stackdriver-project-id field specifies the stackdriver project ID. This
      # field is optional. When running on GCE, application default credentials will be
      # used if this field is not provided.
      metrics.stackdriver-project-id: "<your stackdriver project id>"

      # metrics.allow-stackdriver-custom-metrics indicates whether it is allowed to send metrics to
      # Stackdriver using "global" resource type and custom metric type if the
      # metrics are not supported by "knative_revision" resource type. Setting this
      # flag to "true" could cause extra Stackdriver charge.
      # If metrics.backend-destination is not Stackdriver, this is ignored.
      metrics.allow-stackdriver-custom-metrics: "false"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"_example":"################################\n#                              #\n#    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\n# This block is not actually functional configuration,\n# but serves to illustrate the available configuration\n# options and document them in a way that is accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample configuration options may be copied out of\n# this example block and unindented to be in the data block\n# to actually change the configuration.\n\n# logging.enable-var-log-collection defaults to false.\n# A fluentd sidecar will be set up to collect var log if\n# this flag is true.\nlogging.enable-var-log-collection: false\n\n# logging.fluentd-sidecar-image provides the fluentd sidecar image\n# to inject as a sidecar to collect logs from /var/log.\n# Must be presented if logging.enable-var-log-collection is true.\nlogging.fluentd-sidecar-image: k8s.gcr.io/fluentd-elasticsearch:v2.0.4\n\n# logging.fluentd-sidecar-output-config provides the configuration\n# for the fluentd sidecar, which will be placed into a configmap and\n# mounted into the fluentd sidecar image.\nlogging.fluentd-sidecar-output-config: |\n  # Parse json log before sending to Elastic Search\n  \u003cfilter **\u003e\n    @type parser\n    key_name log\n    \u003cparse\u003e\n      @type multi_format\n      \u003cpattern\u003e\n        format json\n        time_key fluentd-time # fluentd-time is reserved for structured logs\n        time_format %Y-%m-%dT%H:%M:%S.%NZ\n      \u003c/pattern\u003e\n      \u003cpattern\u003e\n        format none\n        message_key log\n      \u003c/pattern\u003e\n    \u003c/parse\u003e\n  \u003c/filter\u003e\n  # Send to Elastic Search\n  \u003cmatch **\u003e\n    @id elasticsearch\n    @type elasticsearch\n    @log_level info\n    include_tag_key true\n    # Elasticsearch service is in monitoring namespace.\n    host elasticsearch-logging.knative-monitoring\n    port 9200\n    logstash_format true\n    \u003cbuffer\u003e\n      @type file\n      path /var/log/fluentd-buffers/kubernetes.system.buffer\n      flush_mode interval\n      retry_type exponential_backoff\n      flush_thread_count 2\n      flush_interval 5s\n      retry_forever\n      retry_max_interval 30\n      chunk_limit_size 2M\n      queue_limit_length 8\n      overflow_action block\n    \u003c/buffer\u003e\n  \u003c/match\u003e\n\n# logging.revision-url-template provides a template to use for producing the\n# logging URL that is injected into the status of each Revision.\n# This value is what you might use the the Knative monitoring bundle, and provides\n# access to Kibana after setting up kubectl proxy.\nlogging.revision-url-template: |\n  http://localhost:8001/api/v1/namespaces/knative-monitoring/services/kibana-logging/proxy/app/kibana#/discover?_a=(query:(match:(kubernetes.labels.knative-dev%2FrevisionUID:(query:'${REVISION_UID}',type:phrase))))\n\n# If non-empty, this enables queue proxy writing request logs to stdout.\n# The value determines the shape of the request logs and it must be a valid go text/template.\n# It is important to keep this as a single line. Multiple lines are parsed as separate entities\n# by most collection agents and will split the request logs into multiple records.\n#\n# The following fields and functions are available to the template:\n#\n# Request: An http.Request (see https://golang.org/pkg/net/http/#Request)\n# representing an HTTP request received by the server.\n#\n# Response:\n# struct {\n#   Code    int       // HTTP status code (see https://www.iana.org/assignments/http-status-codes/http-status-codes.xhtml)\n#   Size    int       // An int representing the size of the response.\n#   Latency float64   // A float64 representing the latency of the response in seconds.\n# }\n#\n# Revision:\n# struct {\n#   Name          string  // Knative revision name\n#   Namespace     string  // Knative revision namespace\n#   Service       string  // Knative service name\n#   Configuration string  // Knative configuration name\n#   PodName       string  // Name of the pod hosting the revision\n#   PodIP         string  // IP of the pod hosting the revision\n# }\n#\nlogging.request-log-template: '{\"httpRequest\": {\"requestMethod\": \"{{.Request.Method}}\", \"requestUrl\": \"{{js .Request.RequestURI}}\", \"requestSize\": \"{{.Request.ContentLength}}\", \"status\": {{.Response.Code}}, \"responseSize\": \"{{.Response.Size}}\", \"userAgent\": \"{{js .Request.UserAgent}}\", \"remoteIp\": \"{{js .Request.RemoteAddr}}\", \"serverIp\": \"{{.Revision.PodIP}}\", \"referer\": \"{{js .Request.Referer}}\", \"latency\": \"{{.Response.Latency}}s\", \"protocol\": \"{{.Request.Proto}}\"}, \"traceId\": \"{{index .Request.Header \"X-B3-Traceid\"}}\"}'\n\n# metrics.backend-destination field specifies the system metrics destination.\n# It supports either prometheus (the default) or stackdriver.\n# Note: Using stackdriver will incur additional charges\nmetrics.backend-destination: prometheus\n\n# metrics.request-metrics-backend-destination specifies the request metrics\n# destination. If non-empty, it enables queue proxy to send request metrics.\n# Currently supported values: prometheus, stackdriver.\nmetrics.request-metrics-backend-destination: prometheus\n\n# metrics.stackdriver-project-id field specifies the stackdriver project ID. This\n# field is optional. When running on GCE, application default credentials will be\n# used if this field is not provided.\nmetrics.stackdriver-project-id: \"\u003cyour stackdriver project id\u003e\"\n\n# metrics.allow-stackdriver-custom-metrics indicates whether it is allowed to send metrics to\n# Stackdriver using \"global\" resource type and custom metric type if the\n# metrics are not supported by \"knative_revision\" resource type. Setting this\n# flag to \"true\" could cause extra Stackdriver charge.\n# If metrics.backend-destination is not Stackdriver, this is ignored.\nmetrics.allow-stackdriver-custom-metrics: \"false\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"config-observability","namespace":"knative-eventing"}}
    name: config-observability
    namespace: knative-eventing
- apiVersion: v1
  data:
    _example: |
      ################################
      #                              #
      #    EXAMPLE CONFIGURATION     #
      #                              #
      ################################

      # This block is not actually functional configuration,
      # but serves to illustrate the available configuration
      # options and document them in a way that is accessible
      # to users that `kubectl edit` this config map.
      #
      # These sample configuration options may be copied out of
      # this example block and unindented to be in the data block
      # to actually change the configuration.
      #
      # If true we enable adding spans within our applications.
      enable: "false"

      # URL to zipkin collector where traces are sent.
      zipkin-endpoint: "http://zipkin.istio-system.svc.cluster.local:9411/api/v2/spans"

      # Enable zipkin debug mode. This allows all spans to be sent to the server
      # bypassing sampling.
      debug: "false"

      # Percentage (0-1) of requests to trace
      sample-rate: "0.1"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"_example":"################################\n#                              #\n#    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\n# This block is not actually functional configuration,\n# but serves to illustrate the available configuration\n# options and document them in a way that is accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample configuration options may be copied out of\n# this example block and unindented to be in the data block\n# to actually change the configuration.\n#\n# If true we enable adding spans within our applications.\nenable: \"false\"\n\n# URL to zipkin collector where traces are sent.\nzipkin-endpoint: \"http://zipkin.istio-system.svc.cluster.local:9411/api/v2/spans\"\n\n# Enable zipkin debug mode. This allows all spans to be sent to the server\n# bypassing sampling.\ndebug: \"false\"\n\n# Percentage (0-1) of requests to trace\nsample-rate: \"0.1\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"config-tracing","namespace":"knative-eventing"}}
    name: config-tracing
    namespace: knative-eventing
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"duck.knative.dev/channelable":"true","eventing.knative.dev/release":"v0.7.0"},"name":"imc-channelable-manipulator"},"rules":[{"apiGroups":["messaging.knative.dev"],"resources":["inmemorychannels","inmemorychannels/status"],"verbs":["create","get","list","watch","update","patch"]}]}
    labels:
      duck.knative.dev/channelable: "true"
      eventing.knative.dev/release: v0.7.0
    name: imc-channelable-manipulator
  rules:
  - apiGroups:
    - messaging.knative.dev
    resources:
    - inmemorychannels
    - inmemorychannels/status
    verbs:
    - create
    - get
    - list
    - watch
    - update
    - patch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"imc-controller"},"rules":[{"apiGroups":["messaging.knative.dev"],"resources":["inmemorychannels","inmemorychannels/status"],"verbs":["get","list","watch","update"]},{"apiGroups":["messaging.knative.dev"],"resources":["inmemorychannels/finalizers"],"verbs":["update"]},{"apiGroups":[""],"resources":["services"],"verbs":["get","list","watch","create","update","patch"]},{"apiGroups":[""],"resources":["endpoints"],"verbs":["get","list","watch"]},{"apiGroups":["apps"],"resources":["deployments","deployments/status"],"verbs":["get","list","watch"]},{"apiGroups":[""],"resources":["configmaps"],"verbs":["get","list","watch"]},{"apiGroups":[""],"resources":["events"],"verbs":["create","patch"]}]}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: imc-controller
  rules:
  - apiGroups:
    - messaging.knative.dev
    resources:
    - inmemorychannels
    - inmemorychannels/status
    verbs:
    - get
    - list
    - watch
    - update
  - apiGroups:
    - messaging.knative.dev
    resources:
    - inmemorychannels/finalizers
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - services
    verbs:
    - get
    - list
    - watch
    - create
    - update
    - patch
  - apiGroups:
    - ""
    resources:
    - endpoints
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - apps
    resources:
    - deployments
    - deployments/status
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - configmaps
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"imc-dispatcher"},"rules":[{"apiGroups":["messaging.knative.dev"],"resources":["inmemorychannels","inmemorychannels/status"],"verbs":["get","list","watch"]},{"apiGroups":[""],"resources":["configmaps"],"verbs":["get","list","watch"]},{"apiGroups":["messaging.knative.dev"],"resources":["inmemorychannels/status"],"verbs":["update"]}]}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: imc-dispatcher
  rules:
  - apiGroups:
    - messaging.knative.dev
    resources:
    - inmemorychannels
    - inmemorychannels/status
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - configmaps
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - messaging.knative.dev
    resources:
    - inmemorychannels/status
    verbs:
    - update
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0","messaging.knative.dev/channel":"in-memory-channel","messaging.knative.dev/role":"dispatcher"},"name":"imc-dispatcher","namespace":"knative-eventing"},"spec":{"ports":[{"port":80,"protocol":"TCP","targetPort":8080}],"selector":{"messaging.knative.dev/channel":"in-memory-channel","messaging.knative.dev/role":"dispatcher"}}}
    labels:
      eventing.knative.dev/release: v0.7.0
      messaging.knative.dev/channel: in-memory-channel
      messaging.knative.dev/role: dispatcher
    name: imc-dispatcher
    namespace: knative-eventing
  spec:
    ports:
    - port: 80
      protocol: TCP
      targetPort: 8080
    selector:
      messaging.knative.dev/channel: in-memory-channel
      messaging.knative.dev/role: dispatcher
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"ServiceAccount","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"imc-controller","namespace":"knative-eventing"}}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: imc-controller
    namespace: knative-eventing
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"ServiceAccount","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"imc-dispatcher","namespace":"knative-eventing"}}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: imc-dispatcher
    namespace: knative-eventing
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"imc-controller"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"imc-controller"},"subjects":[{"kind":"ServiceAccount","name":"imc-controller","namespace":"knative-eventing"}]}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: imc-controller
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: imc-controller
  subjects:
  - kind: ServiceAccount
    name: imc-controller
    namespace: knative-eventing
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"imc-dispatcher"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"imc-dispatcher"},"subjects":[{"kind":"ServiceAccount","name":"imc-dispatcher","namespace":"knative-eventing"}]}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: imc-dispatcher
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: imc-dispatcher
  subjects:
  - kind: ServiceAccount
    name: imc-dispatcher
    namespace: knative-eventing
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"imc-controller","namespace":"knative-eventing"},"spec":{"replicas":1,"selector":{"matchLabels":{"messaging.knative.dev/channel":"in-memory-channel","messaging.knative.dev/role":"controller"}},"template":{"metadata":{"labels":{"messaging.knative.dev/channel":"in-memory-channel","messaging.knative.dev/role":"controller"}},"spec":{"containers":[{"env":[{"name":"CONFIG_LOGGING_NAME","value":"config-logging"},{"name":"CONFIG_OBSERVABILITY_NAME","value":"config-observability"},{"name":"METRICS_DOMAIN","value":"knative.dev/inmemorychannel-controller"},{"name":"SYSTEM_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"gcr.io/knative-releases/github.com/knative/eventing/cmd/in_memory/channel_controller@sha256:292b2dddf074ce355f5793f3d4893ad0863152e0783f32c05e7ae50328b1e2e6","name":"controller","volumeMounts":[{"mountPath":"/etc/config-logging","name":"config-logging"}]}],"serviceAccountName":"imc-controller","volumes":[{"configMap":{"name":"config-logging"},"name":"config-logging"}]}}}}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: imc-controller
    namespace: knative-eventing
  spec:
    replicas: 1
    selector:
      matchLabels:
        messaging.knative.dev/channel: in-memory-channel
        messaging.knative.dev/role: controller
    template:
      metadata:
        labels:
          messaging.knative.dev/channel: in-memory-channel
          messaging.knative.dev/role: controller
      spec:
        containers:
        - env:
          - name: CONFIG_LOGGING_NAME
            value: config-logging
          - name: CONFIG_OBSERVABILITY_NAME
            value: config-observability
          - name: METRICS_DOMAIN
            value: knative.dev/inmemorychannel-controller
          - name: SYSTEM_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          image: gcr.io/knative-releases/github.com/knative/eventing/cmd/in_memory/channel_controller@sha256:292b2dddf074ce355f5793f3d4893ad0863152e0783f32c05e7ae50328b1e2e6
          name: controller
          volumeMounts:
          - mountPath: /etc/config-logging
            name: config-logging
        serviceAccountName: imc-controller
        volumes:
        - configMap:
            name: config-logging
          name: config-logging
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"imc-dispatcher","namespace":"knative-eventing"},"spec":{"replicas":1,"selector":{"matchLabels":{"messaging.knative.dev/channel":"in-memory-channel","messaging.knative.dev/role":"dispatcher"}},"template":{"metadata":{"labels":{"messaging.knative.dev/channel":"in-memory-channel","messaging.knative.dev/role":"dispatcher"}},"spec":{"containers":[{"env":[{"name":"CONFIG_LOGGING_NAME","value":"config-logging"},{"name":"CONFIG_OBSERVABILITY_NAME","value":"config-observability"},{"name":"METRICS_DOMAIN","value":"knative.dev/inmemorychannel-dispatcher"},{"name":"SYSTEM_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"gcr.io/knative-releases/github.com/knative/eventing/cmd/in_memory/channel_dispatcher@sha256:0c95cafd668283cb045fa4941922ff7365f8e6caef623a9c5a68452be1404b5e","name":"dispatcher","volumeMounts":[{"mountPath":"/etc/config-logging","name":"config-logging"}]}],"serviceAccountName":"imc-dispatcher","volumes":[{"configMap":{"name":"config-logging"},"name":"config-logging"}]}}}}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: imc-dispatcher
    namespace: knative-eventing
  spec:
    replicas: 1
    selector:
      matchLabels:
        messaging.knative.dev/channel: in-memory-channel
        messaging.knative.dev/role: dispatcher
    template:
      metadata:
        labels:
          messaging.knative.dev/channel: in-memory-channel
          messaging.knative.dev/role: dispatcher
      spec:
        containers:
        - env:
          - name: CONFIG_LOGGING_NAME
            value: config-logging
          - name: CONFIG_OBSERVABILITY_NAME
            value: config-observability
          - name: METRICS_DOMAIN
            value: knative.dev/inmemorychannel-dispatcher
          - name: SYSTEM_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          image: gcr.io/knative-releases/github.com/knative/eventing/cmd/in_memory/channel_dispatcher@sha256:0c95cafd668283cb045fa4941922ff7365f8e6caef623a9c5a68452be1404b5e
          name: dispatcher
          volumeMounts:
          - mountPath: /etc/config-logging
            name: config-logging
        serviceAccountName: imc-dispatcher
        volumes:
        - configMap:
            name: config-logging
          name: config-logging
- apiVersion: eventing.knative.dev/v1alpha1
  kind: ClusterChannelProvisioner
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"eventing.knative.dev/v1alpha1","kind":"ClusterChannelProvisioner","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"in-memory"},"spec":{}}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: in-memory
  spec: {}
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"ServiceAccount","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"in-memory-channel-controller","namespace":"knative-eventing"}}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: in-memory-channel-controller
    namespace: knative-eventing
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"in-memory-channel-controller"},"rules":[{"apiGroups":["eventing.knative.dev"],"resources":["channels","channels/status","clusterchannelprovisioners","clusterchannelprovisioners/status"],"verbs":["get","list","watch","update"]},{"apiGroups":["eventing.knative.dev"],"resources":["channels/finalizers","clusterchannelprovisioners/finalizers"],"verbs":["update"]},{"apiGroups":[""],"resources":["services"],"verbs":["get","list","watch","create"]},{"apiGroups":[""],"resources":["services"],"verbs":["update"]},{"apiGroups":[""],"resources":["events"],"verbs":["create","patch","update"]}]}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: in-memory-channel-controller
  rules:
  - apiGroups:
    - eventing.knative.dev
    resources:
    - channels
    - channels/status
    - clusterchannelprovisioners
    - clusterchannelprovisioners/status
    verbs:
    - get
    - list
    - watch
    - update
  - apiGroups:
    - eventing.knative.dev
    resources:
    - channels/finalizers
    - clusterchannelprovisioners/finalizers
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - services
    verbs:
    - get
    - list
    - watch
    - create
  - apiGroups:
    - ""
    resources:
    - services
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"in-memory-channel-controller"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"in-memory-channel-controller"},"subjects":[{"kind":"ServiceAccount","name":"in-memory-channel-controller","namespace":"knative-eventing"}]}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: in-memory-channel-controller
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: in-memory-channel-controller
  subjects:
  - kind: ServiceAccount
    name: in-memory-channel-controller
    namespace: knative-eventing
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"in-memory-channel-controller","namespace":"knative-eventing"},"spec":{"replicas":1,"selector":{"matchLabels":{"clusterChannelProvisioner":"in-memory-channel","role":"controller"}},"template":{"metadata":{"labels":{"clusterChannelProvisioner":"in-memory-channel","role":"controller"}},"spec":{"containers":[{"env":[{"name":"SYSTEM_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"gcr.io/knative-releases/github.com/knative/eventing/cmd/in_memory/controller@sha256:dfd7b2852c9bc2e391b04193a50a4f635db0e7a4bbd79a20c61199e6880394fe","name":"controller"}],"serviceAccountName":"in-memory-channel-controller"}}}}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: in-memory-channel-controller
    namespace: knative-eventing
  spec:
    replicas: 1
    selector:
      matchLabels:
        clusterChannelProvisioner: in-memory-channel
        role: controller
    template:
      metadata:
        labels:
          clusterChannelProvisioner: in-memory-channel
          role: controller
      spec:
        containers:
        - env:
          - name: SYSTEM_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          image: gcr.io/knative-releases/github.com/knative/eventing/cmd/in_memory/controller@sha256:dfd7b2852c9bc2e391b04193a50a4f635db0e7a4bbd79a20c61199e6880394fe
          name: controller
        serviceAccountName: in-memory-channel-controller
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"ServiceAccount","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"in-memory-channel-dispatcher","namespace":"knative-eventing"}}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: in-memory-channel-dispatcher
    namespace: knative-eventing
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"in-memory-channel-dispatcher"},"rules":[{"apiGroups":["eventing.knative.dev"],"resources":["channels","channels/status"],"verbs":["get","list","watch"]},{"apiGroups":[""],"resources":["configmaps"],"verbs":["get","list","watch"]}]}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: in-memory-channel-dispatcher
  rules:
  - apiGroups:
    - eventing.knative.dev
    resources:
    - channels
    - channels/status
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - configmaps
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"in-memory-channel-dispatcher"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"in-memory-channel-dispatcher"},"subjects":[{"kind":"ServiceAccount","name":"in-memory-channel-dispatcher","namespace":"knative-eventing"}]}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: in-memory-channel-dispatcher
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: in-memory-channel-dispatcher
  subjects:
  - kind: ServiceAccount
    name: in-memory-channel-dispatcher
    namespace: knative-eventing
- apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"Role","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"in-memory-channel-dispatcher","namespace":"knative-eventing"},"rules":[{"apiGroups":[""],"resources":["configmaps"],"verbs":["get","list","watch"]}]}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: in-memory-channel-dispatcher
    namespace: knative-eventing
  rules:
  - apiGroups:
    - ""
    resources:
    - configmaps
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"RoleBinding","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"in-memory-channel-dispatcher","namespace":"knative-eventing"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"Role","name":"in-memory-channel-dispatcher"},"subjects":[{"kind":"ServiceAccount","name":"in-memory-channel-dispatcher","namespace":"knative-eventing"}]}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: in-memory-channel-dispatcher
    namespace: knative-eventing
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: in-memory-channel-dispatcher
  subjects:
  - kind: ServiceAccount
    name: in-memory-channel-dispatcher
    namespace: knative-eventing
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"eventing.knative.dev/release":"v0.7.0"},"name":"in-memory-channel-dispatcher","namespace":"knative-eventing"},"spec":{"replicas":1,"selector":{"matchLabels":{"clusterChannelProvisioner":"in-memory-channel","role":"dispatcher"}},"template":{"metadata":{"labels":{"clusterChannelProvisioner":"in-memory-channel","role":"dispatcher"}},"spec":{"containers":[{"env":[{"name":"SYSTEM_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"gcr.io/knative-releases/github.com/knative/eventing/cmd/in_memory/dispatcher@sha256:345888cb32ce69a45165e02fc87ebfde903fd1d9dfe059892289d66b779e6bee","name":"dispatcher"}],"serviceAccountName":"in-memory-channel-dispatcher"}}}}
    labels:
      eventing.knative.dev/release: v0.7.0
    name: in-memory-channel-dispatcher
    namespace: knative-eventing
  spec:
    replicas: 1
    selector:
      matchLabels:
        clusterChannelProvisioner: in-memory-channel
        role: dispatcher
    template:
      metadata:
        labels:
          clusterChannelProvisioner: in-memory-channel
          role: dispatcher
      spec:
        containers:
        - env:
          - name: SYSTEM_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          image: gcr.io/knative-releases/github.com/knative/eventing/cmd/in_memory/dispatcher@sha256:345888cb32ce69a45165e02fc87ebfde903fd1d9dfe059892289d66b779e6bee
          name: dispatcher
        serviceAccountName: in-memory-channel-dispatcher
kind: List
metadata: {}
