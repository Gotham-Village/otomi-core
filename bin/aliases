. .env/cloud

alias d="docker"
alias aw="aws"
alias az="azure"
alias gc="gcloud"
alias k="kubectl"
alias ksk="k -n kube-system"
alias ki="k -n ingress"
alias kis="k -n istio-system"
alias ks="k -n system"
alias ksh="k -n shared"
alias km="k -n monitoring"
alias ka="k --all-namespaces=true"
alias kaa="ka get po,rs,job,deploy,ds,statefulset,svc"
alias kap="ka get po"
alias kdel="k delete"
alias kcv="k config view"
alias kce="$EDITOR ~/.kube/config"
alias kcg="k config view | grep 'current-context:' | sed -n -e 's/^.*current-context: //p'"
alias kcu="k config use-context"
alias kp="k proxy &"
alias kp="killall kubectl"

img=otomi/tools:1.1.4
d --version &>/dev/null
hasDocker=$?
d ps &>/dev/null
dockerRunning=$?

drun() {
  KUBE=/tmp/kube.cfg
  cp ~/.kube/config $KUBE
  # Update path to google-cloud-sdk, so it can refresh tokens
  sed 's/cmd-path: .*.google-cloud-sdk/cmd-path: \/home\/app\/google-cloud-sdk/' ~/.kube/config >$KUBE
  d run -it --rm -v $PWD:$PWD -v $KUBE:/home/app/.kube/config -v /tmp:/tmp \
    -v ~/.aws:/home/app/.aws \
    -v ~/.azure:/home/app/.azure \
    -v ~/.config/gcloud:/home/app/.config/gcloud \
    -v ~/.helm:/home/app/.helm \
    -e K8S_CONTEXT=$K8S_CONTEXT \
    -e STAGE=$STAGE \
    -w $PWD $img $@
  rm $KUBE
}

alias h="helm"
alias hk="h delete"
alias hf="helmfile"

# if not has docker: ci
if [ $hasDocker -eq 0 ]; then
  echo "Found docker client, assuming developer context."
  if [ $dockerRunning -eq 0 ]; then
    echo "Found docker running, will use $img instead of local tooling"
    unalias h hf hk aw az gc
    alias h="drun helm"
    alias hf="drun helmfile"
    alias hk="drun helm delete"
    alias aw="drun aws"
    alias az="drun azure"
    alias gc="drun gcloud"
  else
    echo "No docker daemon running. Please start and source aliases again."
  fi
fi

function kpk() { ps aux | grep "$@" | awk '{print $2}' | xargs kill; }
function kad() { k delete "$@" --all; }
function kdnp() {
  for ns in default kube-system system monitoring ingress shared; do
    kad networkpolicy -n $ns
  done
}
# force erase all namespaces
function kkns() {
  k proxy &
  k get ns | grep Terminating | awk '{print $1}' | xargs -n1 -- bash -c 'kubectl get ns "$0" -o json | jq "del(.spec.finalizers[0])" > "$0.json"; curl -k -H "Content-Type: application/json" -X PUT --data-binary @"$0.json" "http://127.0.0.1:8001/api/v1/namespaces/$0/finalize" '
  kk
}
# erase entire stack but keep nodes
function kkc() {
  k delete crd $(k get crd | egrep "cert-manager|istio|ory|coreos|knative|velero" | awk '{print $1}')
  hf -e ${CLOUD}-$STAGE destroy
  k delete ns --all
}

kcu ${K8S_CONTEXT}
if [ $? -ne 0 ] && [ "$CLOUD" = "aws" ]; then
  # check if we have a mismatching context for an aws cluster
  chek=$(k config get-contexts | grep $K8S_CONTEXT | awk '{print $1}')
  [ "$chek" = "*" ] && chek=$(k config get-contexts | grep $K8S_CONTEXT | awk '{print $2}')
  aw eks --region $AWS_REGION update-kubeconfig --name $K8S_CONTEXT
  echo "Renaming aws context '$chek' to '$K8S_CONTEXT'"
  k config rename-context $chek $K8S_CONTEXT
  kcu ${K8S_CONTEXT}
fi

function hf_() { hf -e ${CLOUD}-$STAGE $@; }
function hfd() { hf -e ${CLOUD}-dev $@ --skip-deps; }

echo "Aliases loaded for target '$CLOUD'"
